% !TEX ROOT=./main.tex

\section{The Federated Averaging (FedAvg) Algorithm}
We introduce the standard Federated Averaging (FedAvg) algorithm which was first proposed by~\cite{mcmahan2016communication}.
FedAvg updates the model in each device by local Stochastic Gradient Descent (SGD) and sends the latest model to the central server every $E$
steps. The central server conducts a weighted average over the model parameters
received from active devices and broadcasts the latest averaged model to all devices.
Formally, the updates of FedAvg at round $t$ is described as follows:
\begin{align}
\label{eq:fedavg updates}
\vv_{t+1}^{k} & =\vw_{t}^{k}-\alpha_{t}\vg_{t,k}, \hspace{1em}
\mathbf{w}_{t+1}^{k} =\left\{
\begin{array}{ll}
\mathbf{v}_{t+1}^{k} & \text { if } t+1 \notin \mathcal{I}_{E}, \\ 
\sum_{k \in \cS_{t+1}} q_k \mathbf{v}_{t+1}^{k} & \text { if } t+1 \in \mathcal{I}_{E},
\end{array}\right.
\end{align}
where $\vw_t^k$ is the local model parameter maintained in the $k$-th device at the $t$-th iteration and $\vg_{t,k}:=\nabla F_{k}(\vw_{t}^{k},\xi_{t}^{k})$ is the stochastic gradient based on $\xi_{t}^{k}$, the data point sampled from $k$-th deviceâ€™s local data uniformly at random. $\mathcal{I}_{E}=\{E,2E,\dots\}$ is the set of global communication steps, when local parameters from a set of active devices are averaged and broadcast to all devices. We use $\mathcal{S}_{t+1}$ to represent the (random) set of active devices at $t+1$. $q_k$ is a set of averaging weights that are specific to the sampling procedure used to obtain the set of active devices $\mathcal{S}_{t+1}$.

Since federated learning usually involves an enormous amount of 
local devices, it is often more realistic to assume only a subset of 
local devices is active at each communication round (system heterogeneity). In this work,
we consider both the case of \textbf{full participation} where the model is
averaged over all devices at each communication round, in which case $q_k=p_k$ for all $k$ and 
$\mathbf{w}_{t+1}^{k} = \sum_{k=1}^N p_k \mathbf{v}_{t+1}^{k}$ if $t+1 \in \mathcal{I}_{E}$, and
the case of \textbf{partial participation} where $|\cS_{t+1}| < N$. 

With partial participation, we follow~\cite{li2018federated,karimireddy2019scaffold,li2019convergence} and assume that $\cS_{t+1}$ is obtained by one of two types of
sampling schemes to simulate practical scenarios. One scheme establishes $\cS_{t+1}$ by \emph{i.i.d.} sampling the devices with probability $p_k$ with replacement, and uses $q_k=\frac{1}{K}$, where $K=|\mathcal{S}_{t+1}|$, while the other scheme samples $\cS_{t+1}$ uniformly \emph{i.i.d.} from all devices without replacement, and uses $q_k=p_k\frac{N}{K}$.
Both schemes
guarantee that gradient updates in FedAvg are unbiased stochastic versions of
updates in FedAvg with full participation, which is important in the theoretical analysis of convergence. Because the original sampling scheme and weights proposed by \cite{mcmahan2016communication} lacks this nice property, it is not considered in this paper. For 
more details on the notations and setup as well as properties of the two sampling schemes, please refer to Section~\ref{sec:app:notations} in the appendix.
