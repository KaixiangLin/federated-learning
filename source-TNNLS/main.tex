
\documentclass[journal]{IEEEtran}
\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi

\usepackage{slashbox,multirow}
% \usepackage{tikz}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{amsthm}     % for theorems
\usepackage{algorithm,algorithmic}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{time}
\allowdisplaybreaks
\usepackage{amssymb}
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}
\usepackage{balance}
\usepackage{comment}

%%%%%%
\newcommand{\eq}[1]{{Eq~(#1)}}
\newcommand{\figref}[1]{Figure~\ref{#1}}
\newtheorem{theorem}{Theorem}
\newtheorem{thm}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{remark}{Remark}
\newtheorem{proposition}{Proposition}
\newcommand{\lkxcom}[1]{{\color{red}{#1}}}
\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\def\lowcomma{_{\textstyle{,}}}
\def\lowperiod{_{\textstyle.}}

\newcommand{\ov}[1]{{\overline{\mathbf{#1}}}}
\input{bmacros}

\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}


\newtheorem*{assumption*}{Assumption}
\newtheorem*{claim*}{Claim}

% correct bad hyphenation here
\hyphenation{}


\begin{document}

\title{A Unified Linear Speedup Analysis of Stochastic FedAvg and Nesterov-accelerated FedAvg}

\author{Zhaonan Qu$^*$, Kaixiang Lin$^*$, Zhaojian Li, Jiayu Zhou, and Zhengyuan Zhou% <-this % stops a space
\thanks{$^*$ The first two authors contribute equally.}
\thanks{Zhaonan Qu is with the Department of Economics, Stanford University, CA 94305, USA. Email: {zhaonanq}@stanford.edu}% <-this % stops a space
\thanks{Kaixiang Lin was with the Department of Computer Science and Engineering, Michigan State University, Lansing, MI, 48824,
USA. Email: {linkaixi}@msu.edu.
}% <-this % stops a space
\thanks{Zhaojian Li is with the Department of
Mechanical Engineering, Michigan State University, Lansing, MI, 48824,
USA. Email: {lizhaoj1}@msu.edu.}
\thanks{Jiayu Zhou is with the Department of Computer Science and Engineering, Michigan State University, Lansing, MI, 48824,
USA. Email: {jiayuz}@msu.edu.}
\thanks{Zhengyuan Zhou is with the Department of Technology, Operations, and Statistics at Stern School of Business, New York University, New York, NY 10003,
USA. Email: {zzhou}@stern.nyu.edu.}
}



% The paper headers
\markboth{Journal of \LaTeX\ Class Files,~Vol.~14, No.~8, August~2015}%
{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for IEEE Journals}

\maketitle

\begin{abstract}
Federated learning (FL) learns a model jointly from a set of participating devices without sharing each other's privately held data. The characteristics of non-\textit{i.i.d.} data across the network, low device participation, high communication costs, and the mandate that data remain private bring challenges in understanding the convergence of FL algorithms, particularly in regards to how convergence scales with the number of participating devices. In this paper, we focus on Federated Averaging (FedAvg)--arguably the most popular and effective FL algorithm class in use today--and provide a unified and comprehensive study of its convergence rate. Although FedAvg has recently been studied by an emerging line of literature, it remains open as to how FedAvg's convergence scales with the number of participating devices in the fully heterogeneous FL setting--a crucial question whose answer would shed light on the performance of FedAvg in large FL systems. We fill this gap by providing a unified analysis that establishes convergence guarantees for FedAvg under three classes of problems: strongly convex smooth, convex smooth, and overparameterized strongly convex smooth problems. We show that FedAvg enjoys linear speedup in each case, although with different convergence rates and communication efficiencies. While there have been linear speedup results from distributed optimization that assumes full participation, ours are the first to establish linear speedup for FedAvg under both statistical and system heterogeneity.  For strongly convex and convex problems, we also characterize the corresponding convergence rates for the Nesterov accelerated FedAvg algorithm, which are the first linear speedup guarantees for momentum variants of FedAvg in the convex setting. To provably accelerate FedAvg, we design a new momentum-based FL algorithm that further improves the convergence rate in overparameterized linear regression problems. Empirical studies of the algorithms in various settings have supported our theoretical results.
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
Federated learning, Optimization. 
\end{IEEEkeywords}





\IEEEpeerreviewmaketitle


\input{sec_intro}
%\input{sec_relatedwork}
\input{sec_problem}
\input{sec_SGD}
\input{sec_Nesterov}
%\input{sec_overparameterized}
\input{sec_exp}
\input{sec_conclude}

\input{sec_ack}

% \bibliographystyle{IEEE}
\newpage
\bibliographystyle{abbrv}
%\bibliographystyle{unsrt}
\bibliography{ref}



\begin{comment}
  

\begin{IEEEbiography}{Zhaonan Qu}
Biography text here.
\end{IEEEbiography}

% if you will not have a photo at all:
\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{fig/bio_kaixiang.png}}]{Kaixiang Lin}
Dr. Kaixiang Lin is an applied scientist at Amazon Lab 126. Before joining Amazon, 
Kaixiang received his Ph.D. degree in Computer Science at Michigan State University in 2020. 
\end{IEEEbiography}

% insert where needed to balance the two columns on the last page with
% biographies
%\newpage

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{fig/bio_jiayu.png}}]{Jiayu Zhou}
Dr. Jiayu Zhou is an assistant professor at
 Department of Computer Science and Engineering, Michigan State University.
 Before joining MSU, Jiayu was a staff research scientist at Samsung Research
 America. Jiayu received his Ph.D. degree in computer science at Arizona
 State University in 2014. 
\end{IEEEbiography}


\end{comment}



\appendices

\input{sec_appendix}





% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi




% 
% \begin{thebibliography}{1}
% \bibitem{IEEEhowto:kopka}

% \end{thebibliography}

% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}



% that's all folks
\end{document}


