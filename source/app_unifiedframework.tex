% !TEX ROOT=./main.tex



% This section provides a unified proof framework for the convergence analysis of FedAvg and its accelerated variants. To facilitate our presentation of the unified framework,
% we first outline the FedAvg in Alg~\ref{alg:fedavg} and we will take 
% the strongly convex problem as an example to illustrate our analysis. 
% The corresponding proof for general convex functions follows the 
% same framework.  

% The main roadmap of the convergence proof in this work contain the
% following steps. 
% First, the goal of our analysis is to provide the convergence rate 
% of FedAvg and its accelerated variants, which means the we would like
% to show how does the optimality gap decrease as we conduct more 
% iterations 
% First, recall that our goal is to analyze the convergence rate of FedAvg algorithm, i.e., $F(\vw_t) - F^* \leq \cO(1/T)$ in strongly convex 
% case. 
% To prove this bound, we need to connect the optimality gap with the Frobenius norm
% of current model and the optimal model ($\| \vw_t - \vw^*\|^2$). Then, we 
% analyze the one step progress of FedAvg. This step rigorously shows how 
% much the distance between $\vw_{t+1}$ and $\vw^*$ becomes closer when 
% we take one step stochastic gradient descent in FedAvg. More specifically,
% we provide an upper bound of $\|\vw_{t+1} - \vw^*\|^2$ using the previous
% step $\| \vw_t - \vw^*\|^2$. This will justify a solid theoretical foundation for the step in line 9, Alg~\ref{alg:fedavg}. More importantly, our 
% prove also motivate that we should include more clients to accelerate the
% convergence as we show $\cO(1/NT)$.  Notice that this is the central step of our analysis, which is the main source of improvement of our results comparing to 
% prior arts. 
% Using one step progress bound, we can connect $\|\vw_t - \vw^*\|^2$ to 
% $\|\vw_0 - \vw^*\|^2$ by induction. Therefore, we have an upper bound
% of $\|\vw_t - \vw^*\|^2$ and lastly, we can use the upper bound
% of $\|\vw_t - \vw^*\|^2$ to bound the optimality gap. 
% For strongly convex problems, we can easily connect the optimality gap
% and using L-smooth properties. 

% In conclusion, our proof contains two main steps: 1) \textbf{one step progress bound} prove how much progress we have made by taking one step
% SGD in FedAvg. 2) \textbf{Iterative proof} bounds the up to date progress using one step progress bound iteratively. 
To facilitate the understanding of our analysis and highlight the improvement of our work comparing to prior arts, we summarize the general steps 
used in the proofs across the various settings. In this section,
we take the strongly convex case as an example to illustrate our analysis. The corresponding proof for general convex functions follows the 
same framework.  

\begin{algorithm}[h!]\small
\begin{algorithmic}[1]
\STATE \textbf{Server input:} initial model $\vw_0$, initial step size $\alpha_0$, local steps $E$. 
\STATE \textbf{Client input:} 
\FOR {each round $r = 0, 1, ..., R$, where $r = t*E$} 
\STATE  Sample clients $\cS_t \subseteq \{1,...,N\}$
\STATE Broadcast $\vw$ to all clients $k \in \cS_t$
\FOR {each client $k \subseteq \cS_t$}
\STATE initialize local model $\vw_t^k = \vw$
\FOR {$t = r * E + 1, \dots, (r+1)*E$}
\STATE $\vw_{t+1}^{k}  =\vw_{t}^{k}-\alpha_{t}\vg_{t,k}$
\ENDFOR
\ENDFOR
\STATE Average the local models at server end: $\ov{w}_t = \sum_{k\in \cS_t} \vw_t^k$.
\ENDFOR 
\end{algorithmic}
\caption{\textsc{FedAvg}: Federated Averaging}% $S$ = cA3C($\theta, \Theta_v$
\label{alg:fedavg}
\end{algorithm}


\textbf{One step progress bound} \\ 
This step establishes the progress of distance ($\|\ov{w}_{t}-\vw^{\ast}\|^{2}$) to optimal solution after one step SGD update (see line 9, Alg~\ref{alg:fedavg}), as the following equation shows:
\begin{align*}
	\mathbb{E}\|\ov{w}_{t+1}-\vw^{\ast}\|^{2} & \leq \cO(\eta_t\mathbb{E}\|\ov{w}_{t}-\vw^{\ast}\|^{2} + \alpha_t^2 \sigma^2/N + \alpha_t^3E^2G^2).
\end{align*}
% \lkxcom{explain variance here and the improvement?}
The above bound consists of three main ingredients, the distance to optima
in previous step (with $\eta_t \in (0, 1)$ to obtained a contraction bound), 
the variance of stochastic gradients in local clients (second term), the variance
across different clients (third term). 
Notice that the third term in this bound is the primary source of improvement in the rate.  Comparing to the bound in~\cite{li2019convergence}, we improve 
the third term from $\cO(\alpha_t^2E^2G^2)$ to $\cO(\alpha_t^2E^2G^2)$, which enables the linear speedup in the convergence rate.


\textbf{Iterative deduction}\\
This step uses the \textit{one step progress bound} iteratively to 
connect the the current distance to optimal solution with the initial distance ($\|\ov{w}_{0}-\vw^{\ast}\|^{2}$), as follows:
\begin{align*}
	\mathbb{E}\|\ov{w}_{t+1}-\vw^{\ast}\|^{2} & \leq \cO(\mathbb{E}\|\ov{w}_{0}-\vw^{\ast}\|^{2} \frac{1}{T}).
\end{align*}
% \lkxcom{distinguish the difference between strongly convex and general convex?}
Then we can use the distance to optima to upper bound the optimality gap ($F(\vw_t) - F^* \leq \cO(1/T)$), as follows:
\begin{align*}
	\mathbb{E}(F(\ov{w}_{t}))-F^{\ast} & \leq\cO(\mathbb{E}\|\ov{w}_{t}-\vw^{\ast}\|^{2}). 
\end{align*}
The convergence rate of the optimality gap is equally obtained as the convergence rate of the distance to optima.

\textbf{From full participation to partial participation}\\
There are three sources of variances that affect the convergence rate.
The first two sources come from the variances of within local clients and
across clients (second and third term in one step progress bound). 
The partial participation, which involves a sampling procedure, is the third
source of variance. Therefore, comparing to the rate in full participation, this will add another term of variance into the convergence rate, where we follow a similar derivation as in~\cite{li2019convergence}.

