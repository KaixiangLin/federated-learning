\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2019

% ready for submission
\usepackage{neurips_2019}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2019}

% to compile a camera-ready version, add the [final] option, e.g.:
     % \usepackage[final]{neurips_2019}

% to avoid loading the natbib package, add option nonatbib:
%     \usepackage[nonatbib]{neurips_2019}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{amsthm}     % for theorems
\usepackage{algorithm,algorithmic}
\usepackage{mathtools}
\usepackage{amsmath}
\allowdisplaybreaks
\usepackage{amssymb}
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}
\usepackage{balance}

\newcommand{\eq}[1]{{Eq~(#1)}}
\newcommand{\figref}[1]{Figure~\ref{#1}}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{remark}{Remark}
\newcommand{\lkxcom}[1]{{\color{red}{#1}}}

\newcommand{\ov}[1]{{\overline{\mathbf{#1}}}}
\input{bmacros}
\newtheorem*{assumption*}{Assumption}

\title{Unified Convergence Analysis of FedAve on Non-IID Data}

\author{}

\begin{document}

\maketitle

% \tableofcontents
% \begin{abstract}
% \end{abstract}


% converge proof
\input{sec_problem}
\input{sec_overview}

\input{sec_acceleratedFL}

% accelerated FL survey

% paper

\begin{itemize}
	\item On Federated Learning of Deep Networks from Non-IID Data: Parameter Divergence and the Effects of Hyperparametric Methods: empirical evaluation 
	paper, the loss surface could be helpful.
	\item On the Linear Speedup Analysis of Communication Efficient Momentum SGD for Distributed Non-Convex Optimization: Non-convex, smooth, accelerated SGD, Full device particaption.
\end{itemize}

% \newpage
\small
\bibliographystyle{plain}
\bibliography{ref.bib}

\end{document}