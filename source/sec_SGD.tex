% !TEX ROOT=./main.tex



\section{Linear Speedup Analysis of FedAvg}

In this section, we provide convergence analysis of FedAvg with local
SGD updates. We show that for strongly convex and smooth objectives,
the convergence of the optimality gap of averaged parameters across
devices is $O(1/NT)$ where $N$ is the number of active devices during
each communication round, while for convex and smooth objectives,
the rate is $O(1/\sqrt{NT})$. 

\subsection{Strongly Convex and Smooth Objectives}

We first show that FedAvg with local SGD updates has $O(1/NT)$ convergence
rate for $\mu$-strongly convex and $L$-smooth objectives. The result
improves on the $O(1/T)$ result of {[}ICLR{]} with a linear speedup
in the number of devices $N$. Moreover, it implies a distinction
in the choice of $E$ that guarantees this linear speedup for FedAvg
with full and partial device participation. With full participation,
$E$ can be chosen as large as $O(\sqrt{\frac{T}{N}})$ without degrading
the linear speedup in the number of workers. On the other hand, with
partial participation, $E$ must be $O(1)$. 
\begin{theorem}
	Suppose $F_{k}$ is $L$-smooth and $\mu$-strongly convex for all
	$k$, and let $\nu_{\max}=\max_{k}\frac{1}{N}p_{k}$. Let $\kappa=\frac{L}{\mu}$,
	$\gamma=\max\{32\kappa,E\}$ where $E$ is the communication delay,
	and diminishing learning rates $\alpha_{t}=\frac{1}{4\mu(\gamma+t)}$.
	Let $\overline{w}_{T}=\sum_{k=1}^{N}p_{k}w_{T}^{k}$ be the average
	of local parameters at an arbitrary time $T$.
	
	With full device participation, 
	\begin{align*}
	\mathbb{E}F(\overline{w}_{T})-F^{\ast}=O\left(\frac{\kappa\nu_{\max}^{2}\sigma^{2}/\mu}{NT}+\frac{\kappa^{2}E^{2}G^{2}/\mu}{T^{2}}\right)
	\end{align*}
	and with partial device participation with $K$ sampled devices at
	each communication round, 
	\begin{align*}
	\mathbb{E}F(\overline{w}_{T})-F^{\ast}\leq O\left(\frac{\kappa\nu_{\max}^{2}\sigma^{2}/\mu}{NT}+\frac{\kappa E^{2}G^{2}/\mu}{KT}+\frac{\kappa^{2}E^{2}G^{2}/\mu}{T^{2}}\right)
	\end{align*}
\end{theorem}
%
\begin{remark}
	\textbf{Linear speedup. }We first compare our bound with that in {[}ICLR{]},
	which is $O(\frac{1}{NT}\nu_{\max}^{2}\sigma^{2}\kappa/\mu+\frac{\kappa E^{2}G^{2}/\mu}{KT}+\frac{E^{2}G^{2}}{T}\kappa/\mu)$.
	Because the third term $\frac{E^{2}G^{2}}{T}\kappa/\mu$ is also $O(1/T)$
	without a dependence on $N$, for any choice of $E$ their bound cannot
	achieve linear speedup. The improvement of our bound comes from the
	term $\frac{\kappa^{2}E^{2}G^{2}/\mu}{T^{2}}$, which now is $O(1/T^{2})$.
	As a result, all leading terms scale with $1/N$ in the full device
	particiaption setting, and with $1/K$ in the partial participation
	setting. This implies that in both settings, there is a linear speedup
	in the number of active workers during the communication round.
\end{remark}
%
\begin{remark}
	\textbf{Choice of $E$.} Our bound implies a distinction in the choice
	of $E$ between the full and partial participation settings. In full
	participation, as long as $E=O(\sqrt{\frac{T}{N}})$, the term $\frac{\kappa^{2}E^{2}G^{2}/\mu}{T^{2}}=O(\frac{1}{NT})$,
	which is on the same order as the leading term $\frac{\kappa\nu_{\max}^{2}\sigma^{2}/\mu}{NT}$.
	Thus to achieve a linear speedup in the number of workers $N$, it
	suffices to communicate every $O(\sqrt{\frac{T}{N}})$ iterations.
	In contrast, the bound in {[}ICLR{]} does not allow $E$ to scale
	with $\sqrt{T}$, even for full participation. Thus our bound yields
	a more efficient communication complexity, while at the same time
	providing a linear speedup in the convergence. On the other hand,
	with partial participation, the term $\frac{\kappa E^{2}G^{2}/\mu}{KT}$
	is also a leading term, and so $E$ must be $O(1)$. In this setting,
	our bound still yields a linear speedup in $K$, which is not the
	case for previous analyses. 
\end{remark}

\subsection{Convex Smooth Objectives}

In this section, we provide linear speedup analyses of FedAvg with
convex and smooth objectives and show that the optimality gap is $O(1/\sqrt{NT})$
where $N$ is the number of participating devices. This result complements
the strongly convex case in the previous part, as well as the non-convex
smooth setting in {[}CITE Yu and others{]}, where a similar $O(1/\sqrt{NT})$
rate is given in terms of averaged gradient norm. 
\begin{theorem}
	Suppose $F_{k}$ is $L$-smooth and convex for all $k$, and let $\nu_{\max}=\max_{k}\frac{1}{N}p_{k}$.
	Set learning rate $\alpha_{t}=O\left(\sqrt{\frac{N}{T}}\right)$. With full device participation, 
	\begin{align*}
	\min_{t\leq T}F(\overline{w}_{t})-F(w^{\ast}) & =O\left(\sqrt{\frac{\nu_{\max}^{2}\sigma^{2}}{NT}+\frac{E^{2}LG^{2}}{T^{4/3}}}\right)
	\end{align*}
	and with partial device participation with $K$ sampled devices at
	each communication round, 
	\begin{align*}
	\min_{t\leq T}F(\overline{w}_{t})-F(w^{\ast}) & =O\left(\sqrt{\frac{\nu_{\max}^{2}\sigma^{2}}{NT}+\frac{E^{2}G^{2}}{KT}+\frac{E^{2}LG^{2}}{T^{4/3}}}\right)
	\end{align*}
\end{theorem}

\begin{remark}
	\textbf{Choice of $E$ and linear speedup. }Similar in the strongly
	convex case, we see that in the full participation setting, as long
	as $E=O(\sqrt{\frac{T^{1/3}}{N}})$, the convergence benefits from
	a linear speedup in the number of active workers. In the partial participation
	setting, $E$ must be $O(1)$ in order to allow for linear speedup.
\end{remark}
%
\begin{remark}
	\textbf{Learning rate. }The learning rate now depends on the final
	horizon $T$ of the convergence statement, whereas before the learning
	rate was set to $O(1/t)$ for the $t$-th iteration. We also note
	that the requirement on $\alpha_{t}=O(\sqrt{\frac{N}{T}})$ is also
	present in the work of {[}Yu{]} where they derive similar $O(1/\sqrt{NT})$
	linear speedup convergence results for nonconvex smooth federated
	learning problems.
\end{remark}
For non-smooth objectives, we also have convergence results with rates
$O(1/T)$ and $O(1/\sqrt{T})$ for strongly convex and convex cases,
which can be found in the appendix. Without smoothness, however, the
linear speedup is no longer guaranteed. Together these results complete
the picture of convergence analyses for FedAvg with local SGD updates
for general convex heterogeneous objectives. We next investigate the
convergence of FedAvg with Nesterov updates, and provide similar linear
speedup analyses for convex smooth objectives. 