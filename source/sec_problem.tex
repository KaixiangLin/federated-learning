% !TEX ROOT=./main.tex


\section{Problem Setup}

\subsection{The Federated Learning Problem}

The federated learning problem, given local objectives $F_k$ and device weights $p_k$, is to minimize

\begin{align}
	\min _{\mathbf{w}}\left\{F(\mathbf{w}) \triangleq \sum_{k=1}^{N} p_{k} F_{k}(\mathbf{w})\right\}
	\label{eq:problem}
\end{align}

where $N$ is the number of devices, and device weights $p_k$ satisfy $p_k \geq 0$ and $\sum_{k=1}^N p_k = 1$. Suppose the $k$-th device
holds the $n_k$ data points: $\xi_{k,1}, \xi_{k,2}, \dots, \xi_{k,n_k}$ . We assume that the local objective $F_k(\cdot)$ is defined by

\begin{align}
F_{k}(\mathbf{w}) \triangleq \frac{1}{n_{k}} \sum_{j=1}^{n_{k}} \ell\left(\mathbf{w} ; \xi_{k, j}\right)	
\label{eq:localloss}
\end{align}

where $\ell$ is some loss function. Thus, in the federated learning setting, each device stores its local data, which gives rise to its own local objective $F_k$. A key difference with many problems in the distributed optimization setting is that data on local devices is heterogeneous, i.e. $F_k(w)$ may have different minimizers $w^{\ast}_k$. Moreover, each local device only has access to stochastic gradients based on data stored on the local device. In this paper, we investigate local objectives that are convex or strongly convex and smooth, although convergence results for non-smooth objectives are also given in the appendix. 


\subsection{The FedAvg Algorithm}

Despite the heterogeneity in local objectives, the federated learning
problem can still be solved efficiently in a distributed manner with
the simple Federated Average (FedAvg) algorithm, which consists of
the iterations 

\begin{align}
\vv_{t+1}^{k} & =\vw_{t}^{k}-\alpha_{t}g_{t,k}\\
\vw_{t+1}^{k} & =\begin{cases}
\vv_{t+1}^{k} & \text{if }t+1\notin\mathcal{I}_{E}\\
\sum_{k=1}^{N}p_{k}\vv_{t+1}^{k} & \text{if }t+1\in\mathcal{I}_{E}
\end{cases}
\end{align}

where $\vw_t^k$ is the local model parameter maintained in the $k$-th device during the $t$-th iteration, 
\begin{align}
g_{t,k} & :=\nabla F_{k}(w_{t}^{k},\xi_{t}^{k})
\end{align} 
is the stochastic gradient based on $\xi_{t}^{k}$, the data sampled from k-th deviceâ€™s local data uniformly at random. $\mathcal{I}_{E}=\{E,2E,\dots\}$
is the set of global synchronization steps. Thus when $t+1 \notin \mathcal{I}_{E}$, each device updates its local parameter based on local
stochastic gradient descent, and every $E$ iterations, parameters are aggregated
across devices based on weights $p_{k}$ and then broadcast back to
each local device. 

Communication and broadcasting of local parameters
is costly, so the efficiency of the FedAvg algorithm requires that
$E$ is relatively large, while at the same time ensuring convergence
to a global minimizer of the global objective $\sum_{k}p_{k}F_{k}(w)$. 

In practical applications, it may not be possible to collect local
parameters from \emph{all }devices at a specified communication time.
Thus the above \emph{full participation }FedAvg algorithm may not
be feasible. Instead, a more practical algorithm is to allow only
a random subset $\mathcal{S}_{t+1}$ of all devices to participate in parameter aggregation, while
broadcasting the aggregated parameter to all devices. This gives rise
to the \emph{partial participation }FedAvg algorithm. 

The updates of FedAvg with partial device activation is given by: 
\begin{align} 
\mathbf{v}_{t+1}^{k} &=\mathbf{w}_{t}^{k}-\eta_{t} \nabla F_{k}\left(\mathbf{w}_{t}^{k}, \xi_{t}^{k}\right) \\ \mathbf{w}_{t+1}^{k} &=\left\{\begin{array}{ll}\mathbf{v}_{t+1}^{k} & \text { if } t+1 \notin \mathcal{I}_{E}, \\ 
\sum_{k \in \cS_{t+1}} \mathbf{v}_{t+1}^{k} & \text { if } t+1 \in \mathcal{I}_{E}\end{array}\right.
\end{align}

where $\mathcal{S}_{t+1}$ is obtained using some sampling scheme. We consider two types of common unbiased sampling strategies. The first one samples each device with probability $p_k$, with replacement, while the second one samples each device uniformly without replacement. Both of these sampling schemes guarantee that updates in FedAvg with partial participation are unbiased stochastic versions of updates in FedAvg with full participation, during the communication round.

\subsection{Notation and Assumptions}

Following common practice, we define two virtual sequences $\overline{\mathbf{v}}_{t}$ and $\overline{\mathbf{w}}_{t}$. For full device participation and $t \notin \cI_E$,
$\ov{v}_t = \ov{w}_t =\sum_{k=1}^{N} p_{k} \mathbf{v}_{t}^{k}$. For partial participation, $t \in \cI_E$, $\ov{w}_t \neq \ov{v}_t$ since $\ov{v}_t=\sum_{k=1}^{N} p_{k} \mathbf{v}_{t}^{k}$ while $\ov{w}_t=\sum_{k\in \cS_t}\mathbf{w}_{t}^{k}$. However, we can
set unbiased sampling strategy such that $ \EE_{\cS_t} \ov{w}_t = \ov{v}_t$.
$\overline{\mathbf{v}}_{t+1}$ is one-step SGD from $\overline{\mathbf{w}}_{t}$. 
\begin{align}
\overline{\mathbf{v}}_{t+1}=\overline{\mathbf{w}}_{t}-\eta_{t} \mathbf{g}_{t}	\label{eq:vbar}
\end{align}
% $t+1 \in \cI_E$, we can fetch $\overline{\vw}_{t+1}$, we can communicate $\overline{\vw}_{t+1}$ to all devices.
where $\vg_{t} = \sum_{k=1}^{N} p_{k} \vg_{t,k} $ is one-step stochastic gradient, averaged over all devices. 
\begin{align}
\vg_{t,k} \left\{\begin{array}{ll} 
 = \nabla F_{k}\left(\mathbf{w}_{t}^{k},\xi_{t}^{k} \right)  &  \text{smooth}\\
 \in \partial F_{k}\left(w_{t}^{k}, \xi_{t}^{k}\right)  & \text{non-smooth}
 \end{array}\right.
\end{align}
Similarly, we denote the expected one-step gradient $\ov{g}_{t}= \EE_{\xi_t}[\vg_t] = \sum_{k=1}^{N} p_{k} \EE_{\xi_{t}^{k}} \vg_{t,k}$, where
\begin{align}
\EE_{\xi_{t}^{k}} \vg_{t,k}  \left\{\begin{array}{ll} 
 = \nabla F_{k}\left(\mathbf{w}_{t}^{k}\right)  &  \text{smooth}\\
 \in \partial F_{k}\left(w_{t}^{k}\right)  & \text{non-smooth}
 \end{array}\right.
\end{align}
and $\xi_t = \{\xi_t^k\}_{k=1}^N$ denotes samples at all devices at time step $t$. 

We will require some standard assumptions on the local objectives and their gradients. 

\begin{assumption}[Bounded local variance]
	Let $\xi_{t}^{k}$ be sampled from the $k$-th device's local data uniformly at random. The variance of stochastic gradients in each device is bounded: $\mathbb{E}\left\|\nabla F_{k}\left(\mathbf{w}_{t}^{k}, \xi_{t}^{k}\right)-\nabla F_{k}\left(\mathbf{w}_{t}^{k}\right)\right\|^{2} \leq \sigma_{k}^{2}$,
	for $k=1, \cdots, N$ and any $\mathbf{w}_{t}^{k}$.
\end{assumption}

\begin{assumption}[Expected square norm of gradient]
	The expected squared norm of stochastic gradients is uniformly bounded. i.e.,
	$\mathbb{E}\left\|\nabla F_{k}\left(\mathbf{w}_{t}^{k}, \xi_{t}^{k}\right)\right\|^{2} \leq G^{2}$, for all $k = 1,..., N$ and $t=0, \dots, T-1$.
	\label{ass:subgrad2}
\end{assumption}

\begin{assumption}[L-smooth]
	$F_{1}, \cdots, F_{N}$ are all $L$-smooth: for all  $\mathbf{v}$  and $\mathbf{w}$, $F_{k}(\mathbf{v}) \leq F_{k}(\mathbf{w})+(\mathbf{v}- \\ \mathbf{w})^{T} \nabla F_{k}(\mathbf{w})+\frac{L}{2}\|\mathbf{v}-\mathbf{w}\|_{2}^{2}$.
	\label{ass:lsmooth}
\end{assumption}

\begin{assumption}[Strongly-convex]
	$	F_{1}, \cdots, F_{N} \text { are all } \mu \text { -strongly convex: for all v and } \mathbf{w}, F_{k}(\mathbf{v}) \geq F_{k}(\mathbf{w})+(\mathbf{v}-\mathbf{w})^{T} \nabla F_{k}(\mathbf{w})+\frac{\mu}{2}\|\mathbf{v}-\mathbf{w}\|_{2}^{2}$
	\label{ass:stroncvx}
\end{assumption}

Even though Assumption \ref{ass:subgrad2} also implies $\left\| \mathbb{E}\vg_{t,k}\right\|^2  \leq \mathbb{E}\|\vg_{t,k}\|^2 \leq G_k^2$, which further implies $\mathbb{E}\left\|\nabla F_{k}\left(\mathbf{w}_{t}^{k}, \xi_{t}^{k}\right)-\nabla F_{k}\left(\mathbf{w}_{t}^{k}\right)\right\|^{2} \leq G^2$, the two assumptions are stated separately because it makes explicit the dependence of the optimality gap on different terms. 


