% !TEX ROOT=./main.tex


\section{Setup}

% \subsection{The Federated Learning Problem}

We study the federated learning problem
\begin{align}
	\min _{\mathbf{w}}\left\{F(\mathbf{w}) \triangleq \sum_{k=1}^{N} p_{k} F_{k}(\mathbf{w})\right\},
	\label{eq:problem}
\end{align}
where $N$ is the number of local devices (users/nodes/workers) and $p_k$ is the $k$-th device's weight satisfying $p_k \geq 0$ and $\sum_{k=1}^N p_k = 1$. 
In $k$-th local device, there are a finite number of $n_k$ data points:
$\vx_k^1, \vx_k^2, \dots, \vx_k^{n_k}$.  
The local objective $F_k(\cdot)$ is defined as:
% \begin{align}
$F_{k}(\mathbf{w}) \triangleq \frac{1}{n_{k}} \sum_{j=1}^{n_{k}} \ell\left(\mathbf{w} ; \vx_k^j\right)$,
% \label{eq:localloss}
% \end{align}
where $\ell$ denotes a user-specified loss function. In federated learning, each device stores its local data, which gives rise to its own local objective $F_k$. Note that we do not make any assumption on the
data distributions of each local device. The local minimum
$\vw^{*}_k= \argmin_{\vw \in R^d} F_k(\vw)$ can be drifted far from
the global minimum of \eq{\ref{eq:problem}}, which quantifies the 
heterogeneity of the problem.
In this paper, we systematically investigate the convergence results, 
when the local objectives are convex smooth, strongly convex and convex but
non-smooth.

% A key difference with many problems in the distributed optimization setting is that data on local devices is heterogeneous, i.e. $F_k(w)$ may have different minimizers $w^{\ast}_k$. Moreover, each local device only has access to stochastic gradients based on data stored on the local device. In this paper, we investigate local objectives that are convex or strongly convex and smooth, although convergence results for non-smooth objectives are also given in the appendix. 


\subsection{The Federated Averaging (FedAvg) Algorithm}
We first introduce the standard Federated Average (FedAvg) algorithm.
The FedAvg updates the model in each device by local Stochastic Gradient Descent (SGD) and send the latest model to the central server every $E$
steps. The central server conducts a weighted average over the models
received from active devices and broadcasts the latest averaged model to all devices.
Formally, the updates of FedAvg at round $t$ is described as follows:
\begin{align}
\vv_{t+1}^{k} & =\vw_{t}^{k}-\alpha_{t}\vg_{t,k}\\
\mathbf{w}_{t+1}^{k} &=\left\{
\begin{array}{ll}
\mathbf{v}_{t+1}^{k} & \text { if } t+1 \notin \mathcal{I}_{E}, \\ 
\sum_{k \in \cS_{t+1}} \mathbf{v}_{t+1}^{k} & \text { if } t+1 \in \mathcal{I}_{E}
\end{array}\right.
\end{align}
where $\vw_t^k$ is the local model parameter maintained in the $k$-th device at the $t$-th iteration, $\vg_{t,k}:=\nabla F_{k}(\vw_{t}^{k},\xi_{t}^{k})$ is the stochastic gradient based on $\xi_{t}^{k}$, the data sampled from $k$-th deviceâ€™s local data uniformly at random. $\mathcal{I}_{E}=\{E,2E,\dots\}$ is the set of global synchronization steps. We use $\mathcal{S}_{t+1}$ to represent the set of active devices at $t+1$.

Since federated learning usually involves an enormous amount of 
local devices, it is more realistic to consider only a subset of 
local devices is active at each communication round (system heterogeneity). In this work,
we consider both the case of \textbf{full participation} where the model is
averaging over all devices at the communication round, i.e.,
$\mathbf{w}_{t+1}^{k} = \sum_{k=1}^N p_k \mathbf{v}_{t+1}^{k}$, and
the case of \textbf{partial participation} where $|\cS_{t+1}| < N$. 
In the partial participation scenario, $\cS_{t+1}$ is obtained by two types
sampling schemes to simulate practical scenarios~\cite{li2019convergence}. 
The sampling scheme I establishes $\cS_{t+1}$ by i.i.d. sampling the devices according to
the weight $p_k$ with replacement. 
The sampling scheme II establishes $\cS_{t+1}$ by uniformly sampling all devices without
replacement. Both of the sampling schemes
guarantee that gradient updates in FedAvg are unbiased stochastic versions of
updates in FedAvg with full participation. For 
more details on the notations and setup, please also refer to the Section~\ref{sec:app:notations} in the appendix.

% Thus when $t+1 \notin \mathcal{I}_{E}$, each device updates its local parameter based on local
% stochastic gradient descent, and every $E$ iterations, parameters are aggregated
% across devices based on weights $p_{k}$ and then broadcast back to
% each local device. 

% Communication and broadcasting of local parameters
% is costly, so the efficiency of the FedAvg algorithm requires that
% $E$ is relatively large, while at the same time ensuring convergence
% to a global minimizer of the global objective $\sum_{k}p_{k}F_{k}(w)$. 

% In practical applications, it may not be possible to collect local
% parameters from \emph{all }devices at a specified communication time.
% Thus the above \emph{full participation }FedAvg algorithm may not
% be feasible. Instead, a more practical algorithm is to allow only
% a random subset $\mathcal{S}_{t+1}$ of all devices to participate in parameter aggregation, while
% broadcasting the aggregated parameter to all devices. This gives rise
% to the \emph{partial participation }FedAvg algorithm. 

% The updates of FedAvg with partial device activation is given by: 
% \begin{align} 
% \mathbf{v}_{t+1}^{k} &=\mathbf{w}_{t}^{k}-\eta_{t} \nabla F_{k}\left(\mathbf{w}_{t}^{k}, \xi_{t}^{k}\right) \\ \mathbf{w}_{t+1}^{k} &=\left\{\begin{array}{ll}\mathbf{v}_{t+1}^{k} & \text { if } t+1 \notin \mathcal{I}_{E}, \\ 
% \sum_{k \in \cS_{t+1}} \mathbf{v}_{t+1}^{k} & \text { if } t+1 \in \mathcal{I}_{E}\end{array}\right.
% \end{align}

% where $\mathcal{S}_{t+1}$ is obtained using some sampling scheme. We consider two types of common unbiased sampling strategies. The first one samples each device with probability $p_k$, with replacement, while the second one samples each device uniformly without replacement. Both of these sampling schemes guarantee that updates in FedAvg with partial participation are unbiased stochastic versions of updates in FedAvg with full participation, during the communication round.

\subsection{Assumptions}

We make the following standard assumptions on the objective function $F_1,\dots, F_N$. Assumption~\ref{ass:boundedvariance} and Assumption~\ref{ass:subgrad2} have been made by many prior works in federated learning~\cite{yu2019parallel,li2019convergence,stich2018local}. Assumption~\ref{ass:lsmooth} and Assumption~\ref{ass:stroncvx} are common assumptions satisfied by a range of popular objective functions, such as $l-2$
norm regularized logisitc regressions, logistic regressions and cross-entropy loss functions.  

\begin{assumption}[Bounded local variance]
	Let $\xi_{t}^{k}$ be sampled from the $k$-th device's local data uniformly at random. The variance of stochastic gradients in each device is bounded: $\mathbb{E}\left\|\nabla F_{k}\left(\mathbf{w}_{t}^{k}, \xi_{t}^{k}\right)-\nabla F_{k}\left(\mathbf{w}_{t}^{k}\right)\right\|^{2} \leq \sigma_{k}^{2}$,
	for $k=1, \cdots, N$ and any $\mathbf{w}_{t}^{k}$. Let $\sigma^2=\max_k\sigma_{k}^{2}$.
	\label{ass:boundedvariance}
\end{assumption}
\begin{assumption}[Expected square norm of gradient]
	The expected squared norm of stochastic gradients is uniformly bounded. i.e.,
	$\mathbb{E}\left\|\nabla F_{k}\left(\mathbf{w}_{t}^{k}, \xi_{t}^{k}\right)\right\|^{2} \leq G^{2}$, for all $k = 1,..., N$ and $t=0, \dots, T-1$.
	\label{ass:subgrad2}
\end{assumption}
\begin{assumption}[L-smooth]
	$F_{1}, \cdots, F_{N}$ are all $L$-smooth: for all  $\mathbf{v}$  and $\mathbf{w}$, $F_{k}(\mathbf{v}) \leq F_{k}(\mathbf{w})+(\mathbf{v}- \\ \mathbf{w})^{T} \nabla F_{k}(\mathbf{w})+\frac{L}{2}\|\mathbf{v}-\mathbf{w}\|_{2}^{2}$.
	\label{ass:lsmooth}
\end{assumption}
\begin{assumption}[Strongly-convex]
	$	F_{1}, \cdots, F_{N} \text { are all } \mu \text { -strongly convex: for all v and } \mathbf{w}, F_{k}(\mathbf{v}) \geq F_{k}(\mathbf{w})+(\mathbf{v}-\mathbf{w})^{T} \nabla F_{k}(\mathbf{w})+\frac{\mu}{2}\|\mathbf{v}-\mathbf{w}\|_{2}^{2}$
	\label{ass:stroncvx}
\end{assumption}
Assumption~\ref{ass:lsmooth} is made to achieve linear speedup 
of convergence rate with respect to the number of workers, though it
is not necessary for FedAvg and its variants to convergence.
Assumption \ref{ass:subgrad2} implies $\left\| \mathbb{E}\vg_{t,k}\right\|^2  \leq \mathbb{E}\|\vg_{t,k}\|^2 \leq G_k^2$, which further implies $\mathbb{E}\left\|\nabla F_{k}\left(\mathbf{w}_{t}^{k}, \xi_{t}^{k}\right)-\nabla F_{k}\left(\mathbf{w}_{t}^{k}\right)\right\|^{2} \leq G^2$, the two assumptions are stated separately because it makes explicit the dependence of the optimality gap on different terms. 


