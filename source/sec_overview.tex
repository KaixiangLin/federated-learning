% !TEX ROOT=./main.tex





\section{Proof for Convergence Results on Strongly Convex and Smooth Objectives}

% 	Stochastic gradient of device $k$ at time step $t$, at point $\vw_t^k$: $$\vg_{t,k} \coloneqq \vg_{t,k}(w_t^k)$$
% 	$$ \vg_{t, k} = \grad F_{k}\left(w_{t}^{k}, \xi_{t}^{k}\right) $$
% 	$$\EE \vg_{t, k} = \grad F_{k}\left(w_{t}^{k}\right)$$
%   One-step stochastic subgradient of all devices.
% $$\vg_{t}=\sum_{k=1}^{N} p_{k} \vg_{t, k}\left(w_{t}^{k}\right) $$
% \begin{align}
% 	\EE \vg_{t}= \EE \sum_{k=1}^{N} p_{k} \vg_{t, k}\left(w_{t}^{k}\right) \coloneqq \sum_{k=1}^{N} p_{k} \EE \vg_{t, k}
% 	\label{eq:egtsgd}
% \end{align}


\subsection{Stochastic gradient descent}
\subsubsection{Convex}
\label{sec:convexsmoothsgd}
% \input{sec_convexsmoothsgd}
\input{sec_convexsmoothsgdwthvariance}

% \subsubsection{Convex}
% \label{sec:sgdcvxnonsmth}
\input{sec_cvxnonsm}

\subsection{Strongly Convex}
\input{sec_sgd_scvx_smooth}

\subsection{Stochastic Subgradient methods}
\subsubsection{Convex}
\label{sec:sgdcvxnonsmth}
\input{sec_cvxnonsm}

\subsubsection{Strongly Convex}
\label{sec:sgdscvxnonsmth}
\input{sec_sgdscvxnonsmth}



\section{Accelerated methods}
\subsection{stochastic gradient descent}
\subsubsection{Convex}
\label{sec:nasgdcvxsmth}
\input{sec_nasgd_cvx_smth}

\subsubsection{Strongly Convex}
\label{sec:nasgdscvxsmth}
\input{sec_nasgd_scvx_smooth}

\subsection{Stochastic Subgradient methods}

\subsubsection{Convex}
\label{sec:nasgdcvxnonsmth}
\input{sec_nagcvxnonsmth}

\subsubsection{Strongly Convex}
\label{sec:nasgdscvxnonsmth}
\input{sec_nasgd_scvx_nonsmooth}

\section{Exponential Acceleration of FedAvg in the Interpolation Setting}
\label{sec:interpolation}
\input{sec_interpolation}



