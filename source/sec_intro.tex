% !TEX ROOT=./main.tex


\section{Introduction}
% Motivate FL
The widespread usage of smart home devices and mobile phones constitutes
large-scale distributed networks that generate amount of personal data.
Models learned from such data lead to 
% The emergence of those massive amounts of data has empowered machine learning
% solutions to develop 
many successful applications such as personalized
recommendations~\cite{chen2018federated}, keyboard predictions~\cite{47586},
and etc. Due to the rising awareness of the privacy and rapid growth of
computational power in mobile devices, it becomes increasingly attractive to
push the computation to the edge. Recent years witnessed the rise of
federated learning~\cite{mcmahan2016communication} to fulfill this demand.

% Main challenge in FL.
As a distributed learning paradigm, Federated Learning (FL) collaboratively
learns a single statistical model leveraging the data from all devices while
keeping the training data isolated.  Thus, FL integrates cross-device
information for acquiring improved models without transferring training data from individual devices, thus improves user
privacy~\cite{kairouz2019advances}. Comparing to the traditional distribution optimization,  FL confronts unique
challenges~\cite{li2019convergence,smith2017federated}, including statistical heterogeneity: the data distributions in different devices can be significantly different, and system heterogeneity: only a subset of devices may be accessible to the central server for model training at each time. 

% Gaps in the theoretical understanding. 
To address the aforementioned challenges, Federated
Averaging~\cite{mcmahan2016communication} (FedAvg) was proposed as an
effective heuristic and its great empirical success~\cite{47586} attracted
lots of efforts on building up its theoretical understanding 
and accelerated variants. 
Existing convergence guarantees of FedAvg were largely established on simplified setting~\cite{stich2018local,khaled2019first,wang2018cooperative,yu2019parallel} or provides a suboptimal 
convergence rate~\cite{li2019convergence}. Furthermore, the convergence of
FedAvg's accelerated variants~\cite{yu2019linear,huo2020faster,liu2019accelerating} under the realistic setting is yet to be analyzed.



% Our contributions
% \subsection{Contributions}
\textbf{Contributions.}
This work focus on providing comprehensive convergence analysis
of FedAvg and its accelerated variants under a realistic setting.
Our results show
that the less number of communication rounds is needed to converge to a
target accuracy and preserve the linear speedup w.r.t. participating devices at the same time.
More specifically, for strongly convex and smooth problems, we show 
that FedAvg admits a convergence rate of 
{\small{$\cO(1/NT)$}} convergence, and local steps can be as large as {\small{$\cO(\sqrt{T/N})$}}. For convex and smooth objectives, we show the rate of {\small{$\cO(1/\sqrt{NT})$}} and local steps can be as large as {\small{$\cO(\sqrt{T/N})$}}. 
Moreover, we show that FedAvg with Nesterov acceleration also enjoys the same rates and speedup. 
%The same conclusions are equally applied for Nesterov accelerated FedAvg. 
To the best of our knowledge, this is the first linear speedup results for FedAvg with Nesterov accelerated SGD. Furthermore, 
we provide the first improved convergence rate for Nesterov accelerated FedAvg comparing to FedAvg under the popular overparamterized setting. 
Last but not least, we systematically examine the convergence rate of
FedAvg and it accelerated variants on both a real-world dataset and a synthetic dataset. The empirical observations are well-aligned with theoretical indications.

% Our theoretical results not only cover all general convex objectives, including strongly convex cases, convex smooth cases and convex non-smooth cases, but also provide tighter convergence guarantee for all convex smooth objectives, which shows the convergence rate enjoys a linear speedup w.r.t.
% the number of workers.
% Furthermore, we studied a popular over-parameterized setting~\cite{liu2018accelerating} where the optimal solution can obtain zero training loss. In this scenario, we provide a novel accelerated FL algorithm improving
% the convergence rate of FedAvg. Last but not least, we conduct extensive
% evaluation on both synthetic and real-world dataset, which demonstrates that our theoretical indications is well-aligned with the empirical observations.


\textbf{Notations.}
Throughout the paper, we adopt the following notations. Let $N$ be the total
number of local devices, and $K \leq N$ is the maximal number of devices
that are accessible to the central server.  Let $T$ be the total number of  Stochastic Gradient Descent (SGD) iterations performed by each local device, $E$ be the local steps between two consecutive server communications. Thus, $T/E$ is
the number of communications.

% \textbf{Organization} 
% The reminader of this paper is organized as follows. In Section 




% Intro and related work.
% sec 4. linear speedup of FedAvg,  sec 5. linear speedup of Accelerated FedAvg.
% sec 6 linear regression in 
% 1. this is the first result on the exponential convergence of FedAvg algorithms in the
% interpolation setting with linear speedup in the number of workers and explicit dependence on the
% communication interval E.  
% 2. Improved convergence rate over FedAvg for For the overparamterized quadratic problem. 

% without considering statistical heterogeneity
% or system heterogeneity~\cite{stich2018local,khaled2019first,wang2018cooperative,yu2019parallel,yu2019linear} or suboptimal 
% convergence rate~\cite{li2019convergence}.

% is perhaps the most widely adopted optimization algorithm, which runs local
% Stochastic Gradient Descent (SGD) updates on a subset of devices
% and synchronize the local models once in a while. 
% The empirical success of FedAvg and its variants have
% attracted lots of efforts~\cite{li2018federated,stich2018local,khaled2019first,yu2019parallel,haddadpour2019convergence,li2019convergence,huo2020faster} on analyzing its convergence properties. 
% There are few key challenges that differentiates the theoretical analysis
% of FL from the tradition distribution optimization: 
% 1) The data is non-identically distributed across the workers, which means the
% data in each local device cannot be regarded as samples drawn from
% a same distribution. 
% 2) The workers are not active at every communication
% round. In FL, the central server has no control over the local devices. 
% It is more practical to assume only a subset of workers is active during
% each communication round. 

% The current gaps in FL.
% However, most of prior works~\cite{li2018federated,stich2018local,khaled2019first,yu2019parallel,haddadpour2019convergence} either assume
% the data is identically distributed or the all devices are active, which
% violates the practical characteristic in FL. The most recent work~\cite{li2019convergence} firstly presents $O(1/T)$ convergence guarantee without 
% making those unrealistic assumptions while their analysis focused 
% on strongly convex case only and the relation between the number of active
% workers and the convergence rate is not clearly discussed. 

