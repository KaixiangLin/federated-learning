% !TEX ROOT=./main.tex


\section{Introduction}
Federated learning (FL) is a machine learning setting where many clients (e.g. mobile devices or whole organizations) collaboratively train a model under the orchestration of a central server (e.g. service provider), while keeping the training data decentralized~\cite{kairouz2019advances}.
In recent years, FL has swiftly emerged to be an important learning paradigm~\cite{mcmahan2016communication} --one that enjoys widespread success in applications such as personalized recommendation~\cite{chen2018federated}, virtual assistant~\cite{lamautonomy}, keyboard prediction~\cite{47586} to name a few--for at least two reasons: First, the rapid proliferation of smart devices that are equipped with both computing power and data-capturing capabilities provided the infrastructure core for FL. Second, the rising awareness of privacy and the exponential growth of computational power (blessed by Moore's law) in mobile devices have made it increasingly attractive to push the computation to the edge.

Despite its promise and broad applicability in our current era, the potential value FL delivers is coupled with the unique challenges it brings forth. In particular,
when FL learns a single statistical model using data from across all the devices while keeping each individual device's data isolated (and hence private)~\cite{kairouz2019advances}, it faces two challenges that are absent in centralized optimization and traditional distributed optimization~\cite{li2019convergence,smith2017federated}:
\begin{enumerate}
\item\textbf{Statistical heterogeneity:} data distributions in different devices are different.
\item\textbf{System heterogeneity:} only a subset of devices may access the central server at each time. 
\end{enumerate}

% Gaps in the theoretical understanding. 
To address these challenges, Federated Averaging (FedAvg)~\cite{mcmahan2016communication} was proposed as a particularly effective heuristic, which has enjoyed great empirical success~\cite{47586}. This success has since motivated a growing line of research efforts into understanding its theoretical convergence guarantees in various settings. Most existing convergence guarantees of FedAvg were either established in simplified settings~\cite{stich2018local,khaled2019first,wang2018cooperative,yu2019parallel,khaled2020tighter,li2018federated,koloskova2020unified}, have restrictive assumptions~\cite{haddadpour2019convergence} or provide a suboptimal 
convergence rate~\cite{li2019convergence}. Furthermore, the convergence of
FedAvg's accelerated variants~\cite{yu2019linear,huo2020faster,liu2019accelerating} in the general heterogeneous and convex setting is unknown. At the heart of the success of FL is the \emph{linear speedup} property with respect to the number of participating clients that can be achieved with infrequent communications. Although theoretical results of this kind are abundant in distributed and decentralized optimization~\cite{yu2019linear,yu2019parallel,stich2018local,khaled2020tighter,koloskova2020unified}, generalization to the FL setting with both types of heterogeneity is currently lacking.

\subsection{Related Works}
\textbf{Convergence of FedAvg}
There have been a considerable amount of convergence results in distributed stochastic optimization with infrequent communications that establish linear speedup in the number of clients. However, most of these prior works provide
convergence guarantees under simplified settings, where either statistical
heterogeneity~\cite{stich2018local,zhou2017convergence,wang2018cooperative,woodworth2018graph,haddadpour2019convergence} or system
heterogeneity~\cite{yu2019parallel,wang2019adaptive,khaled2019first,jiang2018linear,koloskova2020unified} is not
considered, and the associated algorithm is often referred to as local SGD. ~\cite{li2019convergence} is the first to provide convergence of FedAvg for general strongly convex problems considering both statistical heterogeneity and system heterogeneity, yet it
didn't achieve linear speedup \cite{yu2019parallel,haddadpour2019convergence,stich2018local}. In~\cite{haddadpour2019convergence,liang2019variance,huo2020faster,jiang2018linear}, the convergence of FedAvg for non-convex problems has been studied, whereas this paper focuses on convex settings.
\begin{comment}
However, \cite{huo2020faster} did not discuss the linear speedup and the theorems in \cite{haddadpour2019convergence,liang2019variance} failed to cover the accelerated version of
FedAvg. 
\end{comment}

\textbf{Accelerating Stochastic Federated Learning Algorithms.}
% The accelerated SGD methods has achieved optimal convergence rate in strongly convex
% optimization~\cite{nesterov1983method}.
The convergence of accelerated FL algorithms using momentum (Nesterov and Heavy Ball) updates has been studied mostly in non-convex settings~\cite{yu2019linear,huo2020faster}. \cite{yu2019linear} does not consider system heterogeneity, while the result in \cite{huo2020faster} does not have linear speedup. Furthermore, the rates cannot improve over SGD-based algorithms in general. \cite{liu2019accelerating} provides an acceleration result for FedAvg with accelerated GD. \cite{liang2019variance} considers variance reduction based acceleration of FedAvg. This paper considers accelerated FedAvg with momentum-based stochastic updates in general and overparameterized convex settings.

\begin{comment}
	In this work, we provide a novel accelerated FedAvg with improved convergence rates under a popular overparameterized setting. 
\end{comment}




% Our contributions
% \subsection{Contributions}
\subsection{Our Contributions.}
We provide a comprehensive convergence analysis
of FedAvg and its accelerated variants in the presence of both system and statistical heterogeneity (see Table~\ref{tb:convergencerateintro}).
Our results demonstrate the desirable linear speedup property with respect to the number of participating clients.
More specifically, for strongly convex and smooth problems, we show 
that FedAvg admits a convergence rate of 
{\small{$\cO(1/NT)$}}, and local steps can be as large as {\small{$\cO(\sqrt{T/N})$}}. For convex and smooth objectives, the rate is {\small{$\cO(1/\sqrt{NT})$}}. 
Moreover, we show that FedAvg with Nesterov acceleration also enjoys the same rates and speedup. 
%The same conclusions are equally applied for Nesterov accelerated FedAvg. 
To the best of our knowledge, this is the first linear speedup result for FedAvg and accelerated variants in the fully heterogeneous FL setting. Furthermore, 
we propose a new variant of FedAvg and provide the first improved convergence rate for stochastic momentum-accelerated FedAvg in the popular overparamterized setting.
Last but not least, we systematically examine the convergence rate of
FedAvg and its accelerated variants on both a synthetic dataset and  a real-world dataset. The empirical observations are well-aligned with the obtained theoretical findings.


\begin{table}[h!]
\centering
{\small
\begin{tabular}{|c|c|c|c|}\hline 
	Participation \textbackslash\ Objective function            & Strongly Convex        & Convex  & Overparameterized \\ \hline \hline
	Full                         & $\cO(\frac{1}{NT}+\frac{E^{2}}{T^{2}})$    &  $\mathcal{O}\left(\frac{1}{\sqrt{NT}}+\frac{NE^{2}}{T}\right)$   & $\cO(\exp(-\frac{NT}{E}))$    \\ \hline
	Partial                      &  $\cO\left(\frac{E^{2}}{KT}+\frac{E^{2}}{T^{2}}\right)$   &  $\cO\left(\frac{E^2}{\sqrt{KT}}+\frac{KE^2}{T} \right)$ & $\cO(\exp(-\frac{KT}{E}))$     \\ \hline
\end{tabular}
}
\caption{Our convergence results for FedAvg and accelerated FedAvg in this paper.}
\label{tb:convergencerateintro}
\end{table}

% Our theoretical results not only cover all general convex objectives, including strongly convex cases, convex smooth cases and convex non-smooth cases, but also provide tighter convergence guarantee for all convex smooth objectives, which shows the convergence rate enjoys a linear speedup w.r.t.
% the number of workers.
% Furthermore, we studied a popular over-parameterized setting~\cite{liu2018accelerating} where the optimal solution can obtain zero training loss. In this scenario, we provide a novel accelerated FL algorithm improving
% the convergence rate of FedAvg. Last but not least, we conduct extensive
% evaluation on both synthetic and real-world dataset, which demonstrates that our theoretical indications is well-aligned with the empirical observations.


\textbf{Notations.}
Throughout the paper, we adopt the following notations. Let $N$ be the total
number of local devices, and $K \leq N$ is the maximal number of devices
that are accessible to the central server.  Let $T$ be the total number of stochastic updates performed by each local device, $E$ be the local steps between two consecutive server communications. Thus, $T/E$ is
the number of communications.

% \textbf{Organization} 
% The reminader of this paper is organized as follows. In Section 




% Intro and related work.
% sec 4. linear speedup of FedAvg,  sec 5. linear speedup of Accelerated FedAvg.
% sec 6 linear regression in 
% 1. this is the first result on the exponential convergence of FedAvg algorithms in the
% interpolation setting with linear speedup in the number of workers and explicit dependence on the
% communication interval E.  
% 2. Improved convergence rate over FedAvg for For the overparamterized quadratic problem. 

% without considering statistical heterogeneity
% or system heterogeneity~\cite{stich2018local,khaled2019first,wang2018cooperative,yu2019parallel,yu2019linear} or suboptimal 
% convergence rate~\cite{li2019convergence}.

% is perhaps the most widely adopted optimization algorithm, which runs local
% Stochastic Gradient Descent (SGD) updates on a subset of devices
% and synchronize the local models once in a while. 
% The empirical success of FedAvg and its variants have
% attracted lots of efforts~\cite{li2018federated,stich2018local,khaled2019first,yu2019parallel,haddadpour2019convergence,li2019convergence,huo2020faster} on analyzing its convergence properties. 
% There are few key challenges that differentiates the theoretical analysis
% of FL from the tradition distribution optimization: 
% 1) The data is non-identically distributed across the workers, which means the
% data in each local device cannot be regarded as samples drawn from
% a same distribution. 
% 2) The workers are not active at every communication
% round. In FL, the central server has no control over the local devices. 
% It is more practical to assume only a subset of workers is active during
% each communication round. 

% The current gaps in FL.
% However, most of prior works~\cite{li2018federated,stich2018local,khaled2019first,yu2019parallel,haddadpour2019convergence} either assume
% the data is identically distributed or the all devices are active, which
% violates the practical characteristic in FL. The most recent work~\cite{li2019convergence} firstly presents $O(1/T)$ convergence guarantee without 
% making those unrealistic assumptions while their analysis focused 
% on strongly convex case only and the relation between the number of active
% workers and the convergence rate is not clearly discussed. 

