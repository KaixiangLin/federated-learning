% !TEX ROOT=./main.tex


\section{Introduction}
Federated learning (FL) is a machine learning setting where many clients (e.g. mobile devices or whole organizations) collaboratively train a model under the orchestration of a central server (e.g. service provider), while keeping the training data decentralized~\cite{kairouz2019advances}.
In recent years, FL has swiftly emerged to be an important learning paradigm~\cite{mcmahan2016communication}--one that enjoys widespread success in applications such as personalized recommendations~\cite{chen2018federated}, virtual assistants~\cite{lamautonomy}, keyboard predictions~\cite{47586} to name a few--for at least two reasons: First, the rapid proliferation of smart devices that are equipped with both computing power and data-capturing capabilities provided the infrastructure core for FL. Second, the rising awareness of privacy and the exponential growth of computational power (blessed by Moore's law) in mobile devices have made it increasingly attractive to push the computation to the edge.

Despite its promise and broad applicability in our current era, the potential value FL delivers is coupled with the unique challenges it brings forth. In particular,
when FL learns a single statistical model using data from across all the devices while keeping each individual device's data isolated (and hence private)~\cite{kairouz2019advances}, it faces two challenges that are absent in centralized optimization and traditional distributed optimization~\cite{li2019convergence,smith2017federated}:
\begin{enumerate}
\item\textbf{Statistical heterogeneity:} data distributions in different devices are different.
\item\textbf{System heterogeneity:} only a subset of devices may access the central server at each time. 
\end{enumerate}

% Gaps in the theoretical understanding. 
To address these challenges, Federated Averaging (FedAvg)~\cite{mcmahan2016communication} was proposed as a particularly effective heuristic, which has enjoyed great empirical success~\cite{47586}. Its success has since motivated a growing line of research efforts into understanding its theoretical convergence guarantees in various settings.

Existing convergence guarantees of FedAvg were either largely established on simplified settings~\cite{stich2018local,khaled2019first,wang2018cooperative,yu2019parallel} or provides a suboptimal 
convergence rate~\cite{li2019convergence}. Furthermore, the convergence of
FedAvg's accelerated variants~\cite{yu2019linear,huo2020faster,liu2019accelerating} under the realistic setting is yet to be analyzed.

\subsection{Related Work}
\textbf{The Convergence of FedAvg and Linear Speedup.}
There has been a vast amount of convergence analysis for FedAvg in different settings. However, most of the prior works provide the
convergence guarantee under a simplified setting, where either statistical
heterogeneity~\cite{stich2018local,zhou2017convergence,wang2018cooperative,woodworth2018graph} or system
heterogeneity~\cite{yu2019parallel,wang2019adaptive,khaled2019first,jiang2018linear} are not
considered. This simplified setting is also referred as local SGD. 
In~\cite{li2019convergence},
the authors for the first time provide convergence of FedAvg for strongly convex problem considering both statistical heterogeneity and system heterogeneity, yet it
didn't achieve linear speedup. In~\cite{haddadpour2019convergence,liang2019variance,huo2020faster,jiang2018linear}, the convergence of FedAvg for non-convex problems has been studied. 
However, \cite{huo2020faster} did not discuss the linear speedup and the theorems in \cite{haddadpour2019convergence,liang2019variance} failed to cover the accelerated version of
FedAvg. 


\textbf{Federated Learning Beyond Local SGD.}
% The accelerated SGD methods has achieved optimal convergence rate in strongly convex
% optimization~\cite{nesterov1983method}.
In \cite{liu2019accelerating}, the authors provide a convergence rate of accelerated FedAvg for strongly convex problems, while it is considered in full participation setting.
\cite{yu2019linear} and \citep{huo2020faster} provide
convergence guarantee for Nesterov accelerated FedAvg for non-convex. 
However, \cite{yu2019linear} did not consider the system heterogeneity and \cite{huo2020faster} haven't discuss the linear speedup.
Furthermore, the accelerated FedAvg admitting a similar convergence rate as FedAvg in all previous works.  In this work, we provide a novel accelerated FedAvg with improved convergence rates under a popular overparameterized setting. 








% Our contributions
% \subsection{Contributions}
\textbf{Contributions.}
This work focuses on providing comprehensive convergence analysis
of FedAvg and its accelerated variants under a realistic setting.
Our results show
that the less number of communication rounds is needed to converge to a
target accuracy while preserving the linear speedup w.r.t. the number of participating devices.
More specifically, for strongly convex and smooth problems, we show 
that FedAvg admits a convergence rate of 
{\small{$\cO(1/NT)$}}, and local steps can be as large as {\small{$\cO(\sqrt{T/N})$}}. For convex and smooth objectives, we show the rate of {\small{$\cO(1/\sqrt{NT})$}} and local steps can be as large as {\small{$\cO(\sqrt{T/N})$}}. 
Moreover, we show that FedAvg with Nesterov acceleration also enjoys the same rates and speedup. 
%The same conclusions are equally applied for Nesterov accelerated FedAvg. 
To the best of our knowledge, this is the first linear speedup results for FedAvg with Nesterov accelerated SGD. Furthermore, 
we provide the first improved convergence rate for Nesterov accelerated FedAvg comparing to FedAvg under the popular overparamterized setting. 
Last but not least, we systematically examine the convergence rate of
FedAvg and its accelerated variants on both a synthetic dataset and  a real-world dataset. The empirical observations are well-aligned with the obtained theoretical findings.

% Our theoretical results not only cover all general convex objectives, including strongly convex cases, convex smooth cases and convex non-smooth cases, but also provide tighter convergence guarantee for all convex smooth objectives, which shows the convergence rate enjoys a linear speedup w.r.t.
% the number of workers.
% Furthermore, we studied a popular over-parameterized setting~\cite{liu2018accelerating} where the optimal solution can obtain zero training loss. In this scenario, we provide a novel accelerated FL algorithm improving
% the convergence rate of FedAvg. Last but not least, we conduct extensive
% evaluation on both synthetic and real-world dataset, which demonstrates that our theoretical indications is well-aligned with the empirical observations.


\textbf{Notations.}
Throughout the paper, we adopt the following notations. Let $N$ be the total
number of local devices, and $K \leq N$ is the maximal number of devices
that are accessible to the central server.  Let $T$ be the total number of SGD iterations performed by each local device, $E$ be the local steps between two consecutive server communications. Thus, $T/E$ is
the number of communications.

% \textbf{Organization} 
% The reminader of this paper is organized as follows. In Section 




% Intro and related work.
% sec 4. linear speedup of FedAvg,  sec 5. linear speedup of Accelerated FedAvg.
% sec 6 linear regression in 
% 1. this is the first result on the exponential convergence of FedAvg algorithms in the
% interpolation setting with linear speedup in the number of workers and explicit dependence on the
% communication interval E.  
% 2. Improved convergence rate over FedAvg for For the overparamterized quadratic problem. 

% without considering statistical heterogeneity
% or system heterogeneity~\cite{stich2018local,khaled2019first,wang2018cooperative,yu2019parallel,yu2019linear} or suboptimal 
% convergence rate~\cite{li2019convergence}.

% is perhaps the most widely adopted optimization algorithm, which runs local
% Stochastic Gradient Descent (SGD) updates on a subset of devices
% and synchronize the local models once in a while. 
% The empirical success of FedAvg and its variants have
% attracted lots of efforts~\cite{li2018federated,stich2018local,khaled2019first,yu2019parallel,haddadpour2019convergence,li2019convergence,huo2020faster} on analyzing its convergence properties. 
% There are few key challenges that differentiates the theoretical analysis
% of FL from the tradition distribution optimization: 
% 1) The data is non-identically distributed across the workers, which means the
% data in each local device cannot be regarded as samples drawn from
% a same distribution. 
% 2) The workers are not active at every communication
% round. In FL, the central server has no control over the local devices. 
% It is more practical to assume only a subset of workers is active during
% each communication round. 

% The current gaps in FL.
% However, most of prior works~\cite{li2018federated,stich2018local,khaled2019first,yu2019parallel,haddadpour2019convergence} either assume
% the data is identically distributed or the all devices are active, which
% violates the practical characteristic in FL. The most recent work~\cite{li2019convergence} firstly presents $O(1/T)$ convergence guarantee without 
% making those unrealistic assumptions while their analysis focused 
% on strongly convex case only and the relation between the number of active
% workers and the convergence rate is not clearly discussed. 

