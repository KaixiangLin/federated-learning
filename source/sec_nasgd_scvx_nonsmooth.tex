We show that FedAvg with Accelerated SGD has $O(1/T)$ rate under
$\mu$-strong convexity. The FedAv algorithm with Nesterov Accelerated
SGD (NASGD) follows the updates
\begin{align*}
y_{t+1}^{k} & =w_{t}^{k}-\alpha_{t}g_{t,k}\\
w_{t+1}^{k} & =\begin{cases}
y_{t+1}^{k}+\beta_{t}(y_{t+1}^{k}-y_{t}^{k}) & \text{if }t+1\notin\mathcal{I}_{E}\\
\sum_{k=1}^{N}p_{k}\left[y_{t+1}^{k}+\beta_{t}(y_{t+1}^{k}-y_{t}^{k})\right] & \text{if }t+1\in\mathcal{I}_{E}
\end{cases}
\end{align*}
where 
\begin{align*}
g_{t,k} & :=\nabla F_{k}(w_{t}^{k},\xi_{t}^{k})
\end{align*}
is the stochastic gradient. 

Define the virtual sequences $\overline{y}_{t}=\sum_{k=1}^{N}p_{k}y_{t}^{k}$,
$\overline{w}_{t}=\sum_{k=1}^{N}p_{k}w_{t}^{k}$, and $\overline{g}_{t}=\sum_{k=1}^{N}p_{k}\mathbb{E}g_{t,k}$.
We have $\mathbb{E}g_{t}=\overline{g}_{t}$ and $\overline{y}_{t+1}=\overline{w}_{t}-\alpha_{t}g_{t}$,
and $\overline{w}_{t+1}=\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t})$. 
\begin{thm}
	(Full device participation) Suppose $F_{k}$ is $\mu$-strongly convex
	for all $k$. Let $E$ be the communication interval, and learning
	rates 
	\begin{align*}
	\alpha_{t} & =\frac{c}{\mu(E+t)}\\
	\beta_{t} & \leq\alpha_{t}
	\end{align*}
	so that $\alpha_{t}\leq2\alpha_{t+E}$, and where $c$ is small enough
	such that the following hold: 
	\begin{align*}
	\alpha_{t}^{2}+\beta_{t-1}^{2} & \leq\frac{1}{2}\\
	4\alpha_{t-1}^{2} & \leq\alpha_{t}
	\end{align*}
	for all $t\geq0$. Suppose also that $G$ is a constant satisfying
	$\mathbb{E}\|w_{0}-\alpha_{0}g_{0,k}\|^{2}=\mathbb{E}\|w_{0}-\alpha_{0}\nabla F_{k}(w_{0},\xi_{0}^{k})\|^{2}\leq G^{2}$
	for all $k$, and $\mathbb{E}\|\nabla F_{k}(w,\xi_{t}^{k})\|^{2}\leq G^{2}$
	for $w=\overline{w}_{t}$ or $w=w_{t}^{k}$ and all $t,k$.
	
	Then with full device participation, \textbf{
		\begin{align*}
		F(\sum_{t=1}^{T}\frac{2t}{T(T+1)}\overline{w}_{t})-F^{\ast} & \leq\frac{2B'}{\mu(T+1)}
		\end{align*}
	} where
	\begin{align*}
	B' & =6G^{2}+32(E-1)^{2}G^{2}+2K^{2}
	\end{align*}
	and $K$ is such that 
	\begin{align*}
	\alpha_{0}B+2K\cdot G & \leq\mu K^{2}\\
	B & =6G^{2}+32(E-1)^{2}G^{2}
	\end{align*}
	and
	\begin{align*}
	K & \geq\max\{\|w_{0}-w^{\ast}\|^{2},\frac{G}{2\alpha_{0}}\}
	\end{align*}
\end{thm}
\begin{proof}
	First, we derive a bound on $\mathbb{E}\|\overline{y}_{t+1}-\overline{y}_{t}\|^{2}$
	that is useful in the proof. We have the recursion 
	\begin{align*}
	y_{t+1}^{k}-y_{t}^{k} & =w_{t}^{k}-w_{t-1}^{k}-(\alpha_{t}g_{t,k}-\alpha_{t-1}g_{t-1,k})\\
	w_{t+1}^{k}-w_{t}^{k} & =-\alpha_{t}g_{t,k}+\beta_{t}(y_{t+1}^{k}-y_{t}^{k})
	\end{align*}
	so that 
	\begin{align*}
	y_{t+1}^{k}-y_{t}^{k} & =-\alpha_{t-1}g_{t-1,k}+\beta_{t-1}(y_{t}^{k}-y_{t-1}^{k})-(\alpha_{t}g_{t,k}-\alpha_{t-1}g_{t-1,k})\\
	& =\beta_{t-1}(y_{t}^{k}-y_{t-1}^{k})-\alpha_{t}g_{t,k}
	\end{align*}
	Since the identity $y_{t+1}^{k}-y_{t}^{k}=\beta_{t-1}(y_{t}^{k}-y_{t-1}^{k})-\alpha_{t}g_{t,k}$
	implies 
	\begin{align*}
	\mathbb{E}\|y_{t+1}^{k}-y_{t}^{k}\|^{2} & \leq2\beta_{t-1}^{2}\mathbb{E}\|y_{t}^{k}-y_{t-1}^{k}\|^{2}+2\alpha_{t}^{2}G^{2}
	\end{align*}
	as long as $\alpha_{t},\beta_{t}$ satisfy $2\beta_{t-1}^{2}+2\alpha_{t}^{2}\leq1$,
	and\textbf{ $\mathbb{E}\|w_{0}-\alpha_{0}g_{0,k}\|^{2}\leq G^{2}$},
	we can guarantee that $\mathbb{E}\|y_{t}^{k}-y_{t-1}^{k}\|^{2}\leq G^{2}$.
	This together with Jensen's inequality implies $\mathbb{E}\|\overline{y}_{t}-\overline{y}_{t-1}\|^{2}\leq G^{2}$. 
	
	Our main step is to prove the bound 
	\begin{align*}
	\mathbb{E}\|\overline{w}_{t+1}-w^{\ast}\|^{2} & \leq(1-\mu\alpha_{t})\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}+9L\alpha_{t}^{2}\Gamma+\alpha_{t}^{2}\sum_{k=1}^{N}p_{k}^{2}\sigma_{k}^{2}+32\alpha_{t}^{2}(E-1)^{2}G^{2}\\
	& +2\alpha_{t}^{2}G^{2}+2\beta_{t}\mathbb{E}|\langle\overline{w}_{t}-w^{\ast},(\overline{y}_{t+1}-\overline{y}_{t})\rangle|\\
	& \leq(1-\mu\alpha_{t})\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}+\alpha_{t}^{2}B'
	\end{align*}
	where $B'$ is define in the statement of the theorem. We have 
	\begin{align*}
	\|\overline{w}_{t+1}-w^{\ast}\|^{2} & =\|\overline{w}_{t}-w^{\ast}-\alpha_{t}g_{t}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t})\|^{2}\\
	& =\|\overline{w}_{t}-w^{\ast}\|^{2}+2\langle\overline{w}_{t}-w^{\ast},\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t})-\alpha_{t}g_{t}\rangle+\|\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t})-\alpha_{t}g_{t}\|^{2}\\
	& \leq\|\overline{w}_{t}-w^{\ast}\|^{2}+2\langle\overline{w}_{t}-w^{\ast},\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t})-\alpha_{t}g_{t}\rangle+2\|\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t})\|^{2}+2\|\alpha_{t}g_{t}\|^{2}
	\end{align*}
	and the last two terms satisfy 
	\begin{align*}
	\mathbb{E}\left(2\|\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t})\|^{2}+2\|\alpha_{t}g_{t}\|^{2}\right) & \leq4\alpha_{t}^{2}G^{2}
	\end{align*}
	sicne $\beta_{t}\leq\alpha_{t}$, $\|(\overline{y}_{t+1}-\overline{y}_{t})\|^{2}\leq G^{2}$,
	and $\mathbb{E}\|g_{t}\|^{2}=\mathbb{E}\|\sum_{k=1}^{N}p_{k}g_{t,k}\|^{2}\leq\mathbb{E}\sum_{k=1}^{N}p_{k}\|g_{t,k}\|^{2}\leq G^{2}$. 
	
	Now 
	\begin{align*}
	2\mathbb{E}\langle\overline{w}_{t}-w^{\ast},\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t})-\alpha_{t}g_{t}\rangle & =2\beta_{t}\mathbb{E}\langle\overline{w}_{t}-w^{\ast},(\overline{y}_{t+1}-\overline{y}_{t})\rangle-2\alpha_{t}\mathbb{E}\langle\overline{w}_{t}-w^{\ast},g_{t}\rangle
	\end{align*}
	and we first bound $-2\alpha_{t}\mathbb{E}\langle\overline{w}_{t}-w^{\ast},g_{t}\rangle$.
	We have
	\begin{align*}
	-2\alpha_{t}\langle\overline{w}_{t}-w^{\ast},g_{t}\rangle & =-2\alpha_{t}\sum_{k=1}^{N}p_{k}\langle\overline{w}_{t}-w^{\ast},g_{t,k}\rangle\\
	& =-2\alpha_{t}\sum_{k=1}^{N}p_{k}\langle\overline{w}_{t}-w_{t}^{k},g_{t,k}\rangle-2\alpha_{t}\sum_{k=1}^{N}p_{k}\langle w_{t}^{k}-w^{\ast},g_{t,k}\rangle
	\end{align*}
	and again we bound the two terms separately. Using $\|\frac{1}{\sqrt{\alpha_{t}}}(\overline{w}_{t}-w_{t}^{k})-\sqrt{\alpha_{t}}g_{t,k}\|^{2}\geq0$,
	we have
	\begin{align*}
	-2\langle\overline{w}_{t}-w_{t}^{k},g_{t,k}\rangle & \leq\frac{1}{\alpha_{t}}\|\overline{w}_{t}-w_{t}^{k}\|^{2}+\alpha_{t}\|g_{t,k}\|^{2}
	\end{align*}
	
	Letting $\mathbb{E}_{t}$ denote the conditional expectation $\mathbb{E}\left[\cdot\mid\{w_{t}^{k}\}_{k=1}^{N}\right]$,
	i.e. the expectation with respect to the randomness of $\xi_{t}^{k}$s
	in the stochastic gradients, the $\mu$-strong convexity of $F_{k}$
	implies 
	\begin{align*}
	-\mathbb{E}_{t}\langle w_{t}^{k}-w^{\ast},g_{t,k}\rangle & =-\mathbb{E}_{t}\langle w_{t}^{k}-w^{\ast},g_{t}\rangle=-\mathbb{E}_{t}\langle w_{t}^{k}-w^{\ast},\nabla F_{k}(w_{t}^{k},\xi_{t}^{k})\rangle=-\langle w_{t}^{k}-w^{\ast},\nabla F_{k}(w_{t}^{k})\rangle\\
	& \leq-(F_{k}(w_{t}^{k})-F_{k}(w^{\ast}))-\frac{\mu}{2}\|w_{t}^{k}-w^{\ast}\|^{2}
	\end{align*}
	
	Combining the above, it follows that 
	\begin{align*}
	-2\alpha_{t}\mathbb{E}\langle\overline{w}_{t}-w^{\ast},g_{t}\rangle & \le\alpha_{t}\mathbb{E}\sum_{k=1}^{N}p_{k}\left[(\frac{1}{\alpha_{t}}\|\overline{w}_{t}-w_{t}^{k}\|^{2}+\alpha_{t}\|g_{t,k}\|^{2})-2(F_{k}(w_{t}^{k})-F_{k}(w^{\ast}))-\mu\|w_{t}^{k}-w^{\ast}\|^{2}\right]\\
	& =\mathbb{E}\sum_{k=1}^{N}p_{k}\|\overline{w}_{t}-w_{t}^{k}\|^{2}-\mu\alpha_{t}\mathbb{E}\sum_{k=1}^{N}p_{k}\|w_{t}^{k}-w^{\ast}\|^{2}+\alpha_{t}^{2}\mathbb{E}\sum_{k=1}^{N}p_{k}\|g_{t,k}\|^{2}\\
	& -2\alpha_{t}\mathbb{E}\sum_{k=1}^{N}p_{k}(F_{k}(w_{t}^{k})-F_{k}(w^{\ast}))\\
	& \leq\mathbb{E}\sum_{k=1}^{N}p_{k}\|\overline{w}_{t}-w_{t}^{k}\|^{2}-\mu\alpha_{t}\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}+\alpha_{t}^{2}G^{2}-2\alpha_{t}\mathbb{E}\sum_{k=1}^{N}p_{k}(F_{k}(w_{t}^{k})-F_{k}(w^{\ast}))
	\end{align*}
	where we have again used Jensen's inequality on $\sum_{k=1}^{N}p_{k}\|w_{t}^{k}-w^{\ast}\|^{2}$. 
	
	Thus 
	\begin{align*}
	\mathbb{E}\|\overline{w}_{t+1}-w^{\ast}\|^{2} & \leq(1-\mu\alpha_{t})\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}+\mathbb{E}\sum_{k=1}^{N}p_{k}\|\overline{w}_{t}-w_{k}^{t}\|^{2}-2\alpha_{t}\mathbb{E}\sum_{k=1}^{N}p_{k}(F_{k}(w_{t}^{k})-F_{k}(w^{\ast}))\\
	& +5\alpha_{t}^{2}G^{2}+2\beta_{t}\mathbb{E}\langle\overline{w}_{t}-w^{\ast},(\overline{y}_{t+1}-\overline{y}_{t})\rangle
	\end{align*}
	We note that 
	\begin{align*}
	\mathbb{E}\sum_{k=1}^{N}p_{k}\|\overline{w}_{t}-w_{k}^{t}\|^{2} & \leq16(E-1)^{2}\alpha_{t}^{2}G^{2}
	\end{align*}
	by the same argument as in the proof for the strongly convex and
	smooth case. Now we bound 
	\begin{align*}
	-2\alpha_{t}\mathbb{E}\sum_{k=1}^{N}p_{k}(F_{k}(w_{t}^{k})-F_{k}(w^{\ast})) & \leq-2\alpha_{t}\mathbb{E}\sum_{k=1}^{N}p_{k}(F_{k}(w_{t}^{k})-F_{k}(w^{\ast}))\\
	& =-2\alpha_{t}\mathbb{E}\sum_{k=1}^{N}p_{k}(F_{k}(w_{t}^{k})-F_{k}(\overline{w}_{k})+F(\overline{w}_{k})-F_{k}(w^{\ast}))\\
	& \leq-2\alpha_{t}\mathbb{E}\sum_{k=1}^{N}p_{k}(\langle w_{t}^{k}-\overline{w}_{k},\nabla F_{k}(\overline{w}_{k})\rangle+F(\overline{w}_{k})-F_{k}(w^{\ast}))\\
	& \leq\mathbb{E}\sum_{k=1}^{N}p_{k}\left[\alpha_{t}^{2}\|\nabla F_{k}(\overline{w}_{k})\|^{2}+\|w_{t}^{k}-\overline{w}_{t}^{k}\|^{2}\right]-2\alpha_{t}(F(\overline{w}_{t})-F^{\ast})\\
	& \leq\alpha_{t}^{2}G^{2}+\mathbb{E}\sum_{k=1}^{N}p_{k}\|\overline{w}_{t}-w_{k}^{t}\|^{2}-2\alpha_{t}\mathbb{E}(F(\overline{w}_{t})-F^{\ast})
	\end{align*}
	using convexity of $F_{k}$, the assumption that $\mathbb{E}\|\nabla F_{k}(\overline{w}_{k})\|^{2}\leq G^{2}$. 
	
	Thus 
	\begin{align*}
	\mathbb{E}\|\overline{w}_{t+1}-w^{\ast}\|^{2} & \leq(1-\mu\alpha_{t})\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}+2\mathbb{E}\sum_{k=1}^{N}p_{k}\|\overline{w}_{t}-w_{k}^{t}\|^{2}-2\alpha_{t}\mathbb{E}(F(\overline{w}_{t})-F^{\ast})\\
	& +6\alpha_{t}^{2}G^{2}+2\beta_{t}\mathbb{E}\langle\overline{w}_{t}-w^{\ast},(\overline{y}_{t+1}-\overline{y}_{t})\rangle\\
	& \leq(1-\mu\alpha_{t})\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}+\alpha_{t}^{2}B-2\alpha_{t}\mathbb{E}(F(\overline{w}_{t})-F^{\ast})+2\beta_{t}\mathbb{E}\langle\overline{w}_{t}-w^{\ast},(\overline{y}_{t+1}-\overline{y}_{t})\rangle
	\end{align*}
	where 
	\begin{align*}
	B & =6G^{2}+32(E-1)^{2}G^{2}
	\end{align*}
	
	Now we bound $|2\beta_{t}\mathbb{E}\langle\overline{w}_{t}-w^{\ast},(\overline{y}_{t+1}-\overline{y}_{t})\rangle|$.
	As in the proof for the strongly convex and smooth case, with appropriate
	choice of constant $K$ depending on the other constants, we first
	show that 
	\begin{align*}
	\mathbb{E}\|\overline{w}_{t+1}-w^{\ast}\|^{2} & \leq K^{2}
	\end{align*}
	for all $t$, i.e. the updates always stay in a large ball around
	the optimum during the Nesterov accelerated gradient descent. Note
	that $(F(\overline{w}_{t})-F^{\ast})\geq0$ and 
	\begin{align*}
	\beta_{t}\mathbb{E}\langle\overline{w}_{t}-w^{\ast},(\overline{y}_{t+1}-\overline{y}_{t})\rangle & \leq\beta_{t}\sqrt{\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}}\cdot\sqrt{\mathbb{E}\|\overline{y}_{t+1}-\overline{y}_{t}\|^{2}}
	\end{align*}
	so that 
	\begin{align*}
	\mathbb{E}\|\overline{w}_{t+1}-w^{\ast}\|^{2} & \leq(1-\alpha_{t}\mu)\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}+\alpha_{t}^{2}B+2\beta_{t}\sqrt{\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}}\cdot\sqrt{\mathbb{E}\|\overline{y}_{t+1}-\overline{y}_{t}\|^{2}}\\
	& \leq(1-\alpha_{t}\mu)\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}+\alpha_{t}^{2}B+2\beta_{t}\sqrt{\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}}\cdot G
	\end{align*}
	and again we can conclude that $\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}\leq K^{2}$
	for $t\geq0$, for $K$ satisfying 
	\begin{align*}
	\alpha_{0}B+2K\cdot G & \leq\mu K^{2}
	\end{align*}
	and
	\begin{align*}
	\|w_{0}-w^{\ast}\|^{2} & \leq K^{2}
	\end{align*}
	
	Finally, the bound on $\beta_{t}\mathbb{E}\langle\overline{w}_{t}-w^{\ast},(\overline{y}_{t+1}-\overline{y}_{t})\rangle$
	is exactly the same as in the proof for the strongly convex and smooth
	case, and we may conclude that 
	\begin{align*}
	\mathbb{E}\|\overline{w}_{t+1}-w^{\ast}\|^{2} & \leq(1-\mu\alpha_{t})\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}+\alpha_{t}^{2}B'-2\alpha_{t}\mathbb{E}(F(\overline{w}_{t})-F^{\ast})
	\end{align*}
	where 
	\begin{align*}
	B' & =B+2K^{2}\\
	& =6G^{2}+32(E-1)^{2}G^{2}+2K^{2}
	\end{align*}
	
	To conclude the proof, we apply the averaging trick of the \textbf{TODO:CITE
		LACOSTE paper to get 
		\begin{align*}
		F(\sum_{t=1}^{T}\frac{2t}{T(T+1)}\overline{w}_{t})-F^{\ast} & \leq\frac{2B'}{\mu(T+1)}
		\end{align*}
	}
\end{proof}
%
We now move on to prove the result in the case of partial participation.
Now the FedAvg algorithm with Nesterov Accelerated SGD (NASGD) follows
the updates
\begin{align*}
y_{t+1}^{k} & =w_{t}^{k}-\alpha_{t}g_{t,k}\\
w_{t+1}^{k} & =\begin{cases}
y_{t+1}^{k}+\beta_{t}(y_{t+1}^{k}-y_{t}^{k}) & \text{if }t+1\notin\mathcal{I}_{E}\\
\sum_{k\in\mathcal{S}_{t+1}}\left(y_{t+1}^{k}+\beta_{t}(y_{t+1}^{k}-y_{t}^{k})\right) & \text{if }t+1\in\mathcal{I}_{E}
\end{cases}
\end{align*}
where $\mathcal{S}_{t+1}$ is the multiset obtained by sampling from
$[N]$ according to $p_{k}$, \emph{with replacement, }a total of
$S=|\mathcal{S}_{t+1}|$ times. 

As before we define the virtual sequences $\overline{y}_{t}=\sum_{k=1}^{N}p_{k}y_{t}^{k}$,
$\overline{w}_{t}=\sum_{k=1}^{N}p_{k}w_{t}^{k}$, and $\overline{g}_{t}=\sum_{k=1}^{N}p_{k}\mathbb{E}g_{t,k}$.
We have $\mathbb{E}g_{t}=\overline{g}_{t}$ and $\overline{y}_{t+1}=\overline{w}_{t}-\alpha_{t}g_{t}$,
and as in the full participation case, $\overline{w}_{t+1}=\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t})$
for $t+1\notin\mathcal{I}_{E}$. When $t+1$ is a communication round,
because of the sampling step, this identity is no longer true, but
is true when we take expectation with respect to the sampling distribution
$\mathbb{P}_{\mathcal{S}_{t+1}}$. 
\begin{thm}
	(Partial device participation) Let the parameters satisfy the assumptions
	in the ICLR paper, $\kappa=\frac{L}{\mu}$, $\gamma=\max\{8\kappa,E\}$
	and learning rate $\alpha_{t}=\frac{c}{\mu(\gamma+t)}$, $\beta_{t}\leq\alpha_{t}$
	where $c$ is small enough such that $\alpha_{t}^{2}+\beta_{t-1}^{2}\leq\frac{1}{2}$
	and $2\alpha_{t-1}^{2}\leq\alpha_{t}$ for all $t$. Then with the
	partial device participation scheme described above,
	\begin{align*}
	\mathbb{E}F(w_{T})-F^{\ast} & \leq\frac{2\kappa}{\gamma+T}(\frac{B'+C}{\mu}+2L(\|w_{0}-w^{\ast}\|^{2})\\
	B' & =\sum_{k=1}^{N}p_{k}^{2}\sigma_{k}^{2}+9L\Gamma+32(E-1)^{2}G^{2}+2+2G^{2}+2GK\\
	C & =\frac{16}{S}E^{2}G^{2}
	\end{align*}
	and $K$ is such that 
	\begin{align*}
	\alpha_{0}B+2\sqrt{K}\cdot G & \leq\mu K\\
	B & =\sum_{k=1}^{N}p_{k}^{2}\sigma_{k}^{2}+9L\Gamma+32(E-1)^{2}G^{2}
	\end{align*}
	and
	\begin{align*}
	\|w_{0}-w^{\ast}\|^{2} & \leq K
	\end{align*}
\end{thm}
%
\begin{proof}
	We have
	\begin{align*}
	\|\overline{w}_{t+1}-w^{\ast}\|^{2} & =\|\overline{w}_{t+1}-(\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t}))+(\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t}))-w^{\ast}\|^{2}\\
	& =\|\overline{w}_{t+1}-(\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t}))\|^{2}+\|(\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t}))-w^{\ast}\|^{2}\\
	& +2\langle\overline{w}_{t+1}-(\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t})),(\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t}))-w^{\ast}\rangle
	\end{align*}
	Note that 
	\begin{align*}
	\mathbb{E}_{\mathcal{S}_{t+1}}\langle\overline{w}_{t+1}-(\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t})),(\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t}))-w^{\ast}\rangle & =0
	\end{align*}
	since 
	\begin{align*}
	\mathbb{E}_{\mathcal{S}_{t+1}}\overline{w}_{t+1} & =\mathbb{E}_{\mathcal{S}_{t+1}}\frac{1}{S}\sum_{k\in\mathcal{S}_{t+1}}(y_{t+1}^{k}+\beta_{t}(y_{t+1}^{k}-y_{t}^{k}))\\
	& =\frac{1}{S}\sum_{k\in\mathcal{S}_{t+1}}\mathbb{E}_{\mathcal{S}_{t+1}}(y_{t+1}^{k}+\beta_{t}(y_{t+1}^{k}-y_{t}^{k}))\\
	& =\frac{1}{S}\cdot S\cdot\sum_{k=1}^{N}p_{k}(y_{t+1}^{k}+\beta_{t}(y_{t+1}^{k}-y_{t}^{k}))\\
	& =\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t})
	\end{align*}
	Moreover, if $t+1\notin\mathcal{I}_{E}$, $\|\overline{w}_{t+1}-(\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t}))\|^{2}=0$
	as well, while if $t+1\notin\mathcal{I}_{E}$, we show that 
	\begin{align*}
	\mathbb{E}\|\overline{w}_{t+1}-(\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t}))\|^{2} & =O(\alpha_{t}^{2})
	\end{align*}
	assuming $\eta_{t}$ is non-increasing and $\eta_{t}\leq2\eta_{t+E}$
	for all $t\geq0$. We have 
	\begin{align*}
	\mathbb{E}_{\mathcal{S}_{t+1}}\|\overline{w}_{t+1}-(\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t}))\|^{2} & =\mathbb{E}_{\mathcal{S}_{t+1}}\|\frac{1}{S}\sum_{k\in\mathcal{S}_{t+1}}(y_{t+1}^{k}+\beta_{t}(y_{t+1}^{k}-y_{t}^{k}))-(\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t}))\|^{2}\\
	& =\frac{1}{S^{2}}\sum_{k\in\mathcal{S}_{t+1}}\mathbb{E}_{\mathcal{S}_{t+1}}\|y_{t+1}^{k}+\beta_{t}(y_{t+1}^{k}-y_{t}^{k})-(\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t}))\|^{2}\\
	& =\frac{1}{S}\sum_{k=1}^{N}p_{k}\|y_{t+1}^{k}+\beta_{t}(y_{t+1}^{k}-y_{t}^{k})-(\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t}))\|^{2}
	\end{align*}
	where we have used the general fact that $\mathbb{E}\|\frac{1}{S}\sum_{k\in\mathcal{S}_{t+1}}x_{k}-\mathbb{E}x_{k}\|^{2}=\frac{1}{S^{2}}\sum_{k\in\mathcal{S}_{t+1}}\mathbb{E}\|x_{k}-\mathbb{E}x_{k}\|^{2}$
	for $x_{k}$ iid. Since $t+1\in\mathcal{I}_{E}$, we know that $t_{0}=t-E+1\in\mathcal{I}_{E}$
	is also a communication round, so that $w_{t_{0}}^{k}\equiv\overline{w}_{t_{0}}$
	does not depend on $k$. Then 
	\begin{align*}
	\sum_{k=1}^{N}p_{k}\|y_{t+1}^{k}+\beta_{t}(y_{t+1}^{k}-y_{t}^{k})-(\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t}))\|^{2} & =\sum_{k=1}^{N}p_{k}\|y_{t+1}^{k}+\beta_{t}(y_{t+1}^{k}-y_{t}^{k})-\overline{w}_{t_{0}}+\overline{w}_{t_{0}}-(\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t}))\|^{2}\\
	& \leq\sum_{k=1}^{N}p_{k}\|y_{t+1}^{k}+\beta_{t}(y_{t+1}^{k}-y_{t}^{k})-\overline{w}_{t_{0}}\|^{2}
	\end{align*}
	so that 
	\begin{align*}
	\mathbb{E}\|\overline{w}_{t+1}-(\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t}))\|^{2} & \leq\frac{1}{S}\sum_{k=1}^{N}p_{k}\mathbb{E}\|y_{t+1}^{k}+\beta_{t}(y_{t+1}^{k}-y_{t}^{k})-\overline{w}_{t_{0}}\|^{2}\\
	& =\frac{1}{S}\sum_{k=1}^{N}p_{k}\mathbb{E}\|y_{t+1}^{k}+\beta_{t}(y_{t+1}^{k}-y_{t}^{k})-w_{t_{0}}^{k}\|^{2}\\
	& =\frac{1}{S}\sum_{k=1}^{N}p_{k}\mathbb{E}\|\sum_{i=t_{0}}^{t}\beta_{i}(y_{i+1}^{k}-y_{i}^{k})-\sum_{i=t_{0}}^{t}\alpha_{i}g_{i,k}\|^{2}\\
	& \leq\frac{2}{S}\left[\sum_{k=1}^{N}p_{k}\mathbb{E}\sum_{i=t_{0}}^{t}E\alpha_{i}^{2}\|g_{i,k}\|^{2}+\sum_{k=1}^{N}p_{k}\mathbb{E}\sum_{i=t_{0}}^{t}E\beta_{i}^{2}\|(y_{i+1}^{k}-y_{i}^{k})\|^{2}\right]\\
	& \leq\frac{16}{S}\alpha_{t}^{2}E^{2}G^{2}
	\end{align*}
	Now we turn to $\mathbb{E}\|(\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t}))-w^{\ast}\|^{2}$.
	This term is bounded in the proof of the full participation case,
	with 
	\begin{align*}
	\mathbb{E}\|\overline{w}_{t+1}-w^{\ast}\|^{2} & \leq(1-\mu\alpha_{t})\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}+\alpha_{t}^{2}B'
	\end{align*}
	where 
	\begin{align*}
	B' & =B+2G^{2}+2GK\\
	& =\sum_{k=1}^{N}p_{k}^{2}\sigma_{k}^{2}+9L\Gamma+32(E-1)^{2}G^{2}+2+2G^{2}+2GK
	\end{align*}
	and $K$ is chosen so that 
	\begin{align*}
	\alpha_{0}B+2\sqrt{K}\cdot G & \leq\mu K
	\end{align*}
	and
	\begin{align*}
	\|w_{0}-w^{\ast}\|^{2} & \leq K
	\end{align*}
	
	Now we can conclude that 
	\begin{align*}
	\mathbb{E}\|\overline{w}_{t+1}-w^{\ast}\|^{2} & \leq(1-\mu\alpha_{t})\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}+\alpha_{t}^{2}(B'+C)
	\end{align*}
	where 
	\begin{align*}
	C & =\frac{16}{S}E^{2}G^{2}
	\end{align*}
	
	The exact argument then yields 
	\begin{align*}
	\mathbb{E}F(w_{T})-F^{\ast} & \leq\frac{2\kappa}{\gamma+T}(\frac{B'+C}{\mu}+2L(\|w_{0}-w^{\ast}\|^{2})
	\end{align*}
\end{proof}