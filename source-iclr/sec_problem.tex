% !TEX ROOT=./main.tex


\section{Setup}

% \subsection{The Federated Learning Problem}

In this paper, we study the following federated learning problem:
\begin{align}
	\min _{\mathbf{w}}\left\{F(\mathbf{w}) \triangleq \sum\nolimits_{k=1}^{N} p_{k} F_{k}(\mathbf{w})\right\},
	\label{eq:problem}
\end{align}
where $N$ is the number of local devices (users/nodes/workers) and $p_k$ is the $k$-th device's weight satisfying $p_k \geq 0$ and $\sum_{k=1}^N p_k = 1$. 
In the $k$-th local device, there are $n_k$ data points:
$\vx_k^1, \vx_k^2, \dots, \vx_k^{n_k}$.  
The local objective $F_k(\cdot)$ is defined as:
% \begin{align}
$F_{k}(\mathbf{w}) \triangleq \frac{1}{n_{k}} \sum_{j=1}^{n_{k}} \ell\left(\mathbf{w} ; \vx_k^j\right)$,
% \label{eq:localloss}
% \end{align}
where $\ell$ denotes a user-specified loss function. Each device only has access to its local data, which gives rise to its own local objective $F_k$. Note that we do not make any assumptions on the
data distributions of each local device. The local minimum
$F^{*}_k= \min_{\vw} F_k(\vw)$ can be far from
the global minimum of \eq{\ref{eq:problem}} (data heterogeneity).

% A key difference with many problems in the distributed optimization setting is that data on local devices is heterogeneous, i.e. $F_k(w)$ may have different minimizers $w^{\ast}_k$. Moreover, each local device only has access to stochastic gradients based on data stored on the local device. In this paper, we investigate local objectives that are convex or strongly convex and smooth, although convergence results for non-smooth objectives are also given in the appendix. 


\subsection{The Federated Averaging (FedAvg) Algorithm}
We first introduce the standard Federated Averaging (FedAvg)  algorithm which was first proposed by~\cite{mcmahan2016communication}.
FedAvg updates the model in each device by local Stochastic Gradient Descent (SGD) and sends the latest model to the central server every $E$
steps. The central server conducts a weighted average over the model parameters
received from active devices and broadcasts the latest averaged model to all devices.
Formally, the updates of FedAvg at round $t$ is described as follows:
\begin{align}
\label{eq:fedavg updates}
\vv_{t+1}^{k} & =\vw_{t}^{k}-\alpha_{t}\vg_{t,k}, \hspace{1em}
\mathbf{w}_{t+1}^{k} =\left\{
\begin{array}{ll}
\mathbf{v}_{t+1}^{k} & \text { if } t+1 \notin \mathcal{I}_{E}, \\ 
\sum_{k \in \cS_{t+1}} q_k \mathbf{v}_{t+1}^{k} & \text { if } t+1 \in \mathcal{I}_{E},
\end{array}\right.
\end{align}
where $\vw_t^k$ is the local model parameter maintained in the $k$-th device at the $t$-th iteration and $\vg_{t,k}:=\nabla F_{k}(\vw_{t}^{k},\xi_{t}^{k})$ is the stochastic gradient based on $\xi_{t}^{k}$, the data point sampled from $k$-th deviceâ€™s local data uniformly at random. $\mathcal{I}_{E}=\{E,2E,\dots\}$ is the set of global communication steps, when local parameters from a set of active devices are averaged and broadcast to all devices. We use $\mathcal{S}_{t+1}$ to represent the (random) set of active devices at $t+1$. $q_k$ is a set of averaging weights that are specific to the sampling procedure used to obtain the set of active devices $\mathcal{S}_{t+1}$.

Since federated learning usually involves an enormous amount of 
local devices, it is often more realistic to assume only a subset of 
local devices is active at each communication round (system heterogeneity). In this work,
we consider both the case of \textbf{full participation} where the model is
averaged over all devices at each communication round, in which case $q_k=p_k$ for all $k$ and 
$\mathbf{w}_{t+1}^{k} = \sum_{k=1}^N p_k \mathbf{v}_{t+1}^{k}$ if $t+1 \in \mathcal{I}_{E}$, and
the case of \textbf{partial participation} where $|\cS_{t+1}| < N$. 

With partial participation, we follow~\cite{li2019convergence} and~\cite{li2018federated} and assume that $\cS_{t+1}$ is obtained by one of two types of
sampling schemes to simulate practical scenarios. One scheme establishes $\cS_{t+1}$ by \emph{i.i.d.} sampling the devices with probability $p_k$ with replacement, and uses $q_k=\frac{1}{K}$, where $K=|\mathcal{S}_{t+1}|$, while the other scheme samples $\cS_{t+1}$ uniformly \emph{i.i.d.} from all devices without replacement, and uses $q_k=p_k\frac{N}{K}$.
Both schemes
guarantee that gradient updates in FedAvg are unbiased stochastic versions of
updates in FedAvg with full participation, which is important in the theoretical analysis of convergence. Because the original sampling scheme and weights proposed by \cite{mcmahan2016communication} lacks this nice property, it is not considered in this paper. For 
more details on the notations and setup as well as properties of the two sampling schemes, please refer to Section~\ref{sec:app:notations} in the appendix.

% Thus when $t+1 \notin \mathcal{I}_{E}$, each device updates its local parameter based on local
% stochastic gradient descent, and every $E$ iterations, parameters are aggregated
% across devices based on weights $p_{k}$ and then broadcast back to
% each local device. 

% Communication and broadcasting of local parameters
% is costly, so the efficiency of the FedAvg algorithm requires that
% $E$ is relatively large, while at the same time ensuring convergence
% to a global minimizer of the global objective $\sum_{k}p_{k}F_{k}(w)$. 

% In practical applications, it may not be possible to collect local
% parameters from \emph{all }devices at a specified communication time.
% Thus the above \emph{full participation }FedAvg algorithm may not
% be feasible. Instead, a more practical algorithm is to allow only
% a random subset $\mathcal{S}_{t+1}$ of all devices to participate in parameter aggregation, while
% broadcasting the aggregated parameter to all devices. This gives rise
% to the \emph{partial participation }FedAvg algorithm. 

% The updates of FedAvg with partial device activation is given by: 
% \begin{align} 
% \mathbf{v}_{t+1}^{k} &=\mathbf{w}_{t}^{k}-\eta_{t} \nabla F_{k}\left(\mathbf{w}_{t}^{k}, \xi_{t}^{k}\right) \\ \mathbf{w}_{t+1}^{k} &=\left\{\begin{array}{ll}\mathbf{v}_{t+1}^{k} & \text { if } t+1 \notin \mathcal{I}_{E}, \\ 
% \sum_{k \in \cS_{t+1}} \mathbf{v}_{t+1}^{k} & \text { if } t+1 \in \mathcal{I}_{E}\end{array}\right.
% \end{align}

% where $\mathcal{S}_{t+1}$ is obtained using some sampling scheme. We consider two types of common unbiased sampling strategies. The first one samples each device with probability $p_k$, with replacement, while the second one samples each device uniformly without replacement. Both of these sampling schemes guarantee that updates in FedAvg with partial participation are unbiased stochastic versions of updates in FedAvg with full participation, during the communication round.

\subsection{Assumptions}
\label{sec:assumptions}
We make the following standard assumptions on the objective function $F_1,\dots, F_N$. Assumptions~\ref{ass:lsmooth} and~\ref{ass:stroncvx} are commonly satisfied by a range of popular objective functions, such as $\ell^{2}$-regularized logistic regression and cross-entropy loss functions.

 %Assumption~\ref{ass:lsmooth} is made to achieve linear speedup of convergence rate with respect to the number of workers, though it is not necessary for FedAvg and its variants to convergence.

\begin{assumption}[$L$-smooth]
	$F_{1}, \cdots, F_{N}$ are all $L$-smooth: for all  $\mathbf{v}$  and $\mathbf{w}$, $F_{k}(\mathbf{v}) \leq F_{k}(\mathbf{w})+(\mathbf{v}- \\ \mathbf{w})^{T} \nabla F_{k}(\mathbf{w})+\frac{L}{2}\|\mathbf{v}-\mathbf{w}\|_{2}^{2}$.
	\label{ass:lsmooth}
\end{assumption}
\begin{assumption}[Strongly-convex]
	$	F_{1}, \cdots, F_{N} \text { are all } \mu \text { -strongly convex: for all v and } \mathbf{w}, F_{k}(\mathbf{v}) \geq F_{k}(\mathbf{w})+(\mathbf{v}-\mathbf{w})^{T} \nabla F_{k}(\mathbf{w})+\frac{\mu}{2}\|\mathbf{v}-\mathbf{w}\|_{2}^{2}$
	\label{ass:stroncvx}
\end{assumption}
\begin{assumption}[Bounded local variance]
	Let $\xi_{t}^{k}$ be sampled from the $k$-th device's local data uniformly at random. The variance of stochastic gradients in each device is bounded: $\mathbb{E}\left\|\nabla F_{k}\left(\mathbf{w}_{t}^{k}, \xi_{t}^{k}\right)-\nabla F_{k}\left(\mathbf{w}_{t}^{k}\right)\right\|^{2} \leq \sigma_{k}^{2}$,
	for $k=1, \cdots, N$ and any $\mathbf{w}_{t}^{k}$. Let $\sigma^2:=\sum_{k=1}^{N}p_k\sigma_{k}^{2}$.
	\label{ass:boundedvariance}
\end{assumption}
\begin{assumption}[Bounded local gradient]
	The expected squared norm of stochastic gradients is uniformly bounded. i.e.,
	$\mathbb{E}\left\|\nabla F_{k}\left(\mathbf{w}_{t}^{k}, \xi_{t}^{k}\right)\right\|^{2} \leq G^{2}$, for all $k = 1,..., N$ and $t=0, \dots, T-1$.
	\label{ass:subgrad2}
\end{assumption}
Assumptions~\ref{ass:boundedvariance} and~\ref{ass:subgrad2} have been made in many previous
works in federated learning, e.g.~\cite{yu2019parallel,li2019convergence,stich2018local}. We provide further justification for their generality. As model average parameters become
closer to $\mathbf{w}^{\ast}$, the $L$-smoothness property implies
that $\mathbb{E}\|\nabla F_{k}(\mathbf{w}_{t}^{k},\xi_{t}^{k})\|^{2}$
and $\mathbb{E}\|\nabla F_{k}(\mathbf{w}_{t}^{k},\xi_{t}^{k})-\nabla F_{k}(\mathbf{w}_{t}^{k})\|^{2}$
approach $\mathbb{E}\|\nabla F_{k}(\mathbf{w}^{\ast},\xi_{t}^{k})\|^{2}$
and $\mathbb{E}\|\nabla F_{k}(\mathbf{w}^{\ast},\xi_{t}^{k})-\nabla F_{k}(\mathbf{w}^{\ast})\|^{2}$.
Therefore, there is no substantial difference between these assumptions
and assuming the bounds at $\mathbf{w}^{\ast}$ only~\cite{koloskova2020unified}. Furthermore, compared to assuming \textit{bounded gradient diversity} as in related work~\cite{haddadpour2019convergence,li2018federated}, Assumption~\ref{ass:subgrad2} is much less restrictive. When the optimality gap converges to zero,
bounded gradient diversity restricts local objectives to have the same minimizer as the global objective, contradicting the heterogeneous data setting. 
For detailed discussions of our assumptions and additional comparisons with related works, please refer to Appendix Section~\ref{sec:app:comparison}.

% On the other hand, some works such as \cite{haddadpour2019convergence,li2018federated}
% assume bounds on the ``gradient diversity'' or ``dissimilarity'',
% defined as $\frac{\sum_{k}p_{k}\|\nabla F_{k}(\mathbf{w})\|_{2}^{2}}{\|\sum_{k}p_{k}\nabla F_{k}(\mathbf{w})\|_{2}^{2}}$.
% Such assumptions are more restrictive than our assumptions, because
% they effectively require $\nabla F_{k}(\mathbf{w}^{\ast})\equiv0$ for all local
% objectives. For such ``overparameterized'' settings, we will prove
% that the convergence is in fact geometric. 

