We show that FedAvg with Accelerated SGD has $O(1/T)$ rate under
$\mu$-strong convexity. The FedAv algorithm with Nesterov Accelerated
SGD (NASGD) follows the updates
\begin{align*}
y_{t+1}^{k} & =w_{t}^{k}-\alpha_{t}g_{t,k}\\
w_{t+1}^{k} & =\begin{cases}
y_{t+1}^{k}+\beta_{t}(y_{t+1}^{k}-y_{t}^{k}) & \text{if }t+1\notin\mathcal{I}_{E}\\
\sum_{k=1}^{N}p_{k}\left[y_{t+1}^{k}+\beta_{t}(y_{t+1}^{k}-y_{t}^{k})\right] & \text{if }t+1\in\mathcal{I}_{E}
\end{cases}
\end{align*}
where 
\begin{align*}
g_{t,k} & :=\nabla F_{k}(w_{t}^{k},\xi_{t}^{k})
\end{align*}
is the stochastic gradient. 

Define the virtual sequences $\overline{y}_{t}=\sum_{k=1}^{N}p_{k}y_{t}^{k}$,
$\overline{w}_{t}=\sum_{k=1}^{N}p_{k}w_{t}^{k}$, and $\overline{g}_{t}=\sum_{k=1}^{N}p_{k}\mathbb{E}g_{t,k}$.
We have $\mathbb{E}g_{t}=\overline{g}_{t}$ and $\overline{y}_{t+1}=\overline{w}_{t}-\alpha_{t}g_{t}$,
and $\overline{w}_{t+1}=\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t})$. 
\begin{remark}
	The difference between the smooth and non-smooth cases under strong
	convexity lies in the following key properties: with $L$-smoothness,
	we have
	\begin{align*}
	F(w)-F^{\ast} & \leq\frac{L}{2}\|w-w^{\ast}\|^{2}
	\end{align*}
	so that we may show the decay of optimality gap by the convergence
	of parameters. This is not available in the non-smooth case, and in
	order to apply the decay result of $\|\overline{w}_{t}-w^{\ast}\|^{2}$,
	we need to make use of the averaging trick found for example in CITE.
	The more important difference is that the lower bound $\|\nabla F(w)\|^{2}\leq2L(F(w)-F^{\ast})$
	under $L$-smoothness allows us to bound the terms $\|\nabla F_{k}(\overline{w}_{t})\|\leq2L(F_{k}(\overline{w}_{t}))$
	which combined with convexity gives an upper bound on $-2\alpha_{t}\sum_{k=1}^{N}(F_{k}(w_{t}^{k})-F^{\ast})$,
	acrucial quantity in the proof under strong convexity, and this allows
	us to separate out the heterogeneity term $\Gamma$. When we do not
	have $L$-smoothness, in order to upper bound $-2\alpha_{t}\sum_{k=1}^{N}(F_{k}(w_{t}^{k})-F^{\ast})$,
	we must resort to bounding $\mathbb{E}(\|\nabla F_{k}(\overline{w}_{t})\|^{2})$,
	which is different from the assumption $\mathbb{E}(\|g_{t,k}\|^{2})=\mathbb{E}(\|\nabla F_{k}(w_{t}^{k})\|^{2})\leq G^{2}$,
	and requires a possibly stronger assumption. A different approach
	is the following 
	\begin{align*}
	-2\alpha_{t}\sum_{k=1}^{N}(F_{k}(w_{t}^{k})-F^{\ast}) & =-2\alpha_{t}\sum_{k=1}^{N}(F_{k}(w_{t}^{k})-F_{k}^{\ast}+F_{k}^{\ast}-F^{\ast})\\
	& =-2\alpha_{t}\sum_{k=1}^{N}(F_{k}(w_{t}^{k})-F_{k}^{\ast})+2\alpha_{t}\Gamma\\
	& \leq\sum_{k=1}^{N}p_{k}\alpha_{t}^{2}\|\nabla F_{k}(w_{t}^{k})\|^{2}+\|w_{t}^{k}-w^{k,\ast}\|^{2}+2\alpha_{t}\Gamma
	\end{align*}
	and resort to bounding $\mathbb{E}\|w_{t}^{k}-w^{k,\ast}\|^{2}$.
	The problem is that $2\alpha_{t}\Gamma$ is not $O(\alpha_{t}^{2})$,
	and it is unclear how to show $\|w_{t}^{k}-w^{k,\ast}\|^{2}$ converges. 
\end{remark}
\begin{theorem}
	(Full device participation) Suppose $F_{k}$ is $\mu$-strongly convex
	for all $k$. Let $E$ be the communication interval, and learning
	rates 
	\begin{align*}
	\alpha_{t} & =\frac{c}{\mu(E+t)}\\
	\beta_{t} & \leq\alpha_{t}
	\end{align*}
	so that $\alpha_{t}\leq2\alpha_{t+E}$, and where $c$ is small enough
	such that the following hold: 
	\begin{align*}
	\alpha_{t}^{2}+\beta_{t-1}^{2} & \leq\frac{1}{2}\\
	4\alpha_{t-1}^{2} & \leq\alpha_{t}
	\end{align*}
	for all $t\geq0$. Suppose also that $G$ is a constant satisfying
	$\mathbb{E}\|w_{0}-\alpha_{0}g_{0,k}\|^{2}=\mathbb{E}\|w_{0}-\alpha_{0}\nabla F_{k}(w_{0},\xi_{0}^{k})\|^{2}\leq G^{2}$
	for all $k$, and $\mathbb{E}\|\nabla F_{k}(w,\xi_{t}^{k})\|^{2}\leq G^{2}$
	for $w=\overline{w}_{t}$ or $w=w_{t}^{k}$ and all $t,k$.
	
	Then with full device participation, \textbf{
		\begin{align*}
		F(\sum_{t=1}^{T}\frac{2t}{T(T+1)}\overline{w}_{t})-F^{\ast} & \leq\frac{2B'}{\mu(T+1)}
		\end{align*}
	} where
	\begin{align*}
	B' & =6G^{2}+32(E-1)^{2}G^{2}+2K^{2}
	\end{align*}
	and $K$ is such that 
	\begin{align*}
	\alpha_{0}B+2K\cdot G & \leq\mu K^{2}\\
	B & =6G^{2}+32(E-1)^{2}G^{2}
	\end{align*}
	and
	\begin{align*}
	K & \geq\max\{\|w_{0}-w^{\ast}\|^{2},\frac{G}{2\alpha_{0}}\}
	\end{align*}
\end{theorem}
\begin{proof}
	The bounds 
	\begin{align*}
	\mathbb{E}\|y_{t}^{k}-y_{t-1}^{k}\|^{2} & \leq G^{2}\\
	\mathbb{E}\|\overline{y}_{t}-\overline{y}_{t-1}\|^{2} & \leq G^{2}
	\end{align*}
	hold as before. However, we no longer have the upper bound
	\begin{align*}
	\mathbb{E}(F(\overline{w}_{t}))-F^{\ast} & =\mathbb{E}(F(\overline{w}_{t})-F(w^{\ast}))\\
	& \leq\frac{L}{2}\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}
	\end{align*}
	
	Fortunately we can still use an averaging trick to convert the decay
	of $\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}$ into that of $\mathbb{E}(F(\overline{w}_{t}))-F^{\ast}$,
	but this time replacing $\overline{w}_{t}$ with the time-averaged
	version $\sum_{t=1}^{T}\frac{2t}{T(T+1)}\overline{w}_{t}$.
	
	Our main step is to prove the bound 
	\begin{align*}
	\mathbb{E}\|\overline{w}_{t+1}-w^{\ast}\|^{2} & \leq(1-\mu\alpha_{t})\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}+\alpha_{t}^{2}B'
	\end{align*}
	where $B'$ is define in the statement of the theorem. We have 
	\begin{align*}
	\|\overline{w}_{t+1}-w^{\ast}\|^{2} & =\|\overline{w}_{t}-w^{\ast}-\alpha_{t}g_{t}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t})\|^{2}\\
	& =\|\overline{w}_{t}-w^{\ast}\|^{2}+2\langle\overline{w}_{t}-w^{\ast},\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t})-\alpha_{t}g_{t}\rangle+\|\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t})-\alpha_{t}g_{t}\|^{2}\\
	& \leq\|\overline{w}_{t}-w^{\ast}\|^{2}+2\langle\overline{w}_{t}-w^{\ast},\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t})-\alpha_{t}g_{t}\rangle+2\|\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t})\|^{2}+2\|\alpha_{t}g_{t}\|^{2}
	\end{align*}
	and the last two terms satisfy 
	\begin{align*}
	\mathbb{E}\left(2\|\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t})\|^{2}+2\|\alpha_{t}g_{t}\|^{2}\right) & \leq4\alpha_{t}^{2}G^{2}
	\end{align*}
	sicne $\beta_{t}\leq\alpha_{t}$, $\|(\overline{y}_{t+1}-\overline{y}_{t})\|^{2}\leq G^{2}$,
	and $\mathbb{E}\|g_{t}\|^{2}=\mathbb{E}\|\sum_{k=1}^{N}p_{k}g_{t,k}\|^{2}\leq\mathbb{E}\sum_{k=1}^{N}p_{k}\|g_{t,k}\|^{2}\leq G^{2}$. 
	
	Now 
	\begin{align*}
	2\mathbb{E}\langle\overline{w}_{t}-w^{\ast},\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t})-\alpha_{t}g_{t}\rangle & =2\beta_{t}\mathbb{E}\langle\overline{w}_{t}-w^{\ast},(\overline{y}_{t+1}-\overline{y}_{t})\rangle-2\alpha_{t}\mathbb{E}\langle\overline{w}_{t}-w^{\ast},g_{t}\rangle
	\end{align*}
	and we first bound $-2\alpha_{t}\mathbb{E}\langle\overline{w}_{t}-w^{\ast},g_{t}\rangle$.
	We have
	\begin{align*}
	-2\alpha_{t}\langle\overline{w}_{t}-w^{\ast},g_{t}\rangle & =-2\alpha_{t}\sum_{k=1}^{N}p_{k}\langle\overline{w}_{t}-w^{\ast},g_{t,k}\rangle\\
	& =-2\alpha_{t}\sum_{k=1}^{N}p_{k}\langle\overline{w}_{t}-w_{t}^{k},g_{t,k}\rangle-2\alpha_{t}\sum_{k=1}^{N}p_{k}\langle w_{t}^{k}-w^{\ast},g_{t,k}\rangle
	\end{align*}
	and again we bound the two terms separately. Using $\|\frac{1}{\sqrt{\alpha_{t}}}(\overline{w}_{t}-w_{t}^{k})-\sqrt{\alpha_{t}}g_{t,k}\|^{2}\geq0$,
	we have
	\begin{align*}
	-2\langle\overline{w}_{t}-w_{t}^{k},g_{t,k}\rangle & \leq\frac{1}{\alpha_{t}}\|\overline{w}_{t}-w_{t}^{k}\|^{2}+\alpha_{t}\|g_{t,k}\|^{2}
	\end{align*}
	
	Letting $\mathbb{E}_{t}$ denote the conditional expectation $\mathbb{E}\left[\cdot\mid\{w_{t}^{k}\}_{k=1}^{N}\right]$,
	i.e. the expectation with respect to the randomness of $\xi_{t}^{k}$s
	in the stochastic gradients, the $\mu$-strong convexity of $F_{k}$
	implies 
	\begin{align*}
	-\mathbb{E}_{t}\langle w_{t}^{k}-w^{\ast},g_{t,k}\rangle & =-\mathbb{E}_{t}\langle w_{t}^{k}-w^{\ast},g_{t}\rangle=-\mathbb{E}_{t}\langle w_{t}^{k}-w^{\ast},\nabla F_{k}(w_{t}^{k},\xi_{t}^{k})\rangle=-\langle w_{t}^{k}-w^{\ast},\nabla F_{k}(w_{t}^{k})\rangle\\
	& \leq-(F_{k}(w_{t}^{k})-F_{k}(w^{\ast}))-\frac{\mu}{2}\|w_{t}^{k}-w^{\ast}\|^{2}
	\end{align*}
	
	Combining the above, it follows that 
	\begin{align*}
	-2\alpha_{t}\mathbb{E}\langle\overline{w}_{t}-w^{\ast},g_{t}\rangle & \le\alpha_{t}\mathbb{E}\sum_{k=1}^{N}p_{k}\left[(\frac{1}{\alpha_{t}}\|\overline{w}_{t}-w_{t}^{k}\|^{2}+\alpha_{t}\|g_{t,k}\|^{2})-2(F_{k}(w_{t}^{k})-F_{k}(w^{\ast}))-\mu\|w_{t}^{k}-w^{\ast}\|^{2}\right]\\
	& =\mathbb{E}\sum_{k=1}^{N}p_{k}\|\overline{w}_{t}-w_{t}^{k}\|^{2}-\mu\alpha_{t}\mathbb{E}\sum_{k=1}^{N}p_{k}\|w_{t}^{k}-w^{\ast}\|^{2}+\alpha_{t}^{2}\mathbb{E}\sum_{k=1}^{N}p_{k}\|g_{t,k}\|^{2}\\
	& -2\alpha_{t}\mathbb{E}\sum_{k=1}^{N}p_{k}(F_{k}(w_{t}^{k})-F_{k}(w^{\ast}))\\
	& \leq\mathbb{E}\sum_{k=1}^{N}p_{k}\|\overline{w}_{t}-w_{t}^{k}\|^{2}-\mu\alpha_{t}\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}+\alpha_{t}^{2}G^{2}-2\alpha_{t}\mathbb{E}\sum_{k=1}^{N}p_{k}(F_{k}(w_{t}^{k})-F_{k}(w^{\ast}))
	\end{align*}
	where we have again used Jensen's inequality on $\sum_{k=1}^{N}p_{k}\|w_{t}^{k}-w^{\ast}\|^{2}$. 
	
	Thus 
	\begin{align*}
	\mathbb{E}\|\overline{w}_{t+1}-w^{\ast}\|^{2} & \leq(1-\mu\alpha_{t})\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}+\mathbb{E}\sum_{k=1}^{N}p_{k}\|\overline{w}_{t}-w_{k}^{t}\|^{2}-2\alpha_{t}\mathbb{E}\sum_{k=1}^{N}p_{k}(F_{k}(w_{t}^{k})-F_{k}(w^{\ast}))\\
	& +5\alpha_{t}^{2}G^{2}+2\beta_{t}\mathbb{E}\langle\overline{w}_{t}-w^{\ast},(\overline{y}_{t+1}-\overline{y}_{t})\rangle
	\end{align*}
	We note that 
	\begin{align*}
	\mathbb{E}\sum_{k=1}^{N}p_{k}\|\overline{w}_{t}-w_{k}^{t}\|^{2} & \leq16(E-1)^{2}\alpha_{t}^{2}G^{2}
	\end{align*}
	by the same argument as in the proof for the strongly convex and
	smooth case. Now we bound 
	\begin{align*}
	-2\alpha_{t}\mathbb{E}\sum_{k=1}^{N}p_{k}(F_{k}(w_{t}^{k})-F_{k}(w^{\ast})) & \leq-2\alpha_{t}\mathbb{E}\sum_{k=1}^{N}p_{k}(F_{k}(w_{t}^{k})-F_{k}(w^{\ast}))\\
	& =-2\alpha_{t}\mathbb{E}\sum_{k=1}^{N}p_{k}(F_{k}(w_{t}^{k})-F_{k}(\overline{w}_{t})+F(\overline{w}_{t})-F_{k}(w^{\ast}))\\
	& \leq-2\alpha_{t}\mathbb{E}\sum_{k=1}^{N}p_{k}(\langle w_{t}^{k}-\overline{w}_{t},\nabla F_{k}(\overline{w}_{t})\rangle+F(\overline{w}_{t})-F_{k}(w^{\ast}))\\
	& \leq\mathbb{E}\sum_{k=1}^{N}p_{k}\left[\alpha_{t}^{2}\|\nabla F_{k}(\overline{w}_{t})\|^{2}+\|w_{t}^{k}-\overline{w}_{t}^{k}\|^{2}\right]-2\alpha_{t}(F(\overline{w}_{t})-F^{\ast})\\
	& \leq\alpha_{t}^{2}G^{2}+\mathbb{E}\sum_{k=1}^{N}p_{k}\|\overline{w}_{t}-w_{k}^{t}\|^{2}-2\alpha_{t}\mathbb{E}(F(\overline{w}_{t})-F^{\ast})
	\end{align*}
	using convexity of $F_{k}$, the assumption that $\mathbb{E}\|\nabla F_{k}(\overline{w}_{t})\|^{2}\leq G^{2}$.
	This is where the proof differs from the smooth case, where we bounded
	$\|\nabla F_{k}(\overline{w}_{t})\|^{2}\leq2L(F(\overline{w}_{t})-F^{\ast})$. 
	
	Thus 
	\begin{align*}
	\mathbb{E}\|\overline{w}_{t+1}-w^{\ast}\|^{2} & \leq(1-\mu\alpha_{t})\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}+2\mathbb{E}\sum_{k=1}^{N}p_{k}\|\overline{w}_{t}-w_{k}^{t}\|^{2}-2\alpha_{t}\mathbb{E}(F(\overline{w}_{t})-F^{\ast})\\
	& +6\alpha_{t}^{2}G^{2}+2\beta_{t}\mathbb{E}\langle\overline{w}_{t}-w^{\ast},(\overline{y}_{t+1}-\overline{y}_{t})\rangle\\
	& \leq(1-\mu\alpha_{t})\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}+\alpha_{t}^{2}B-2\alpha_{t}\mathbb{E}(F(\overline{w}_{t})-F^{\ast})+2\beta_{t}\mathbb{E}\langle\overline{w}_{t}-w^{\ast},(\overline{y}_{t+1}-\overline{y}_{t})\rangle
	\end{align*}
	where 
	\begin{align*}
	B & =6G^{2}+32(E-1)^{2}G^{2}
	\end{align*}
	
	Now we bound $|2\beta_{t}\mathbb{E}\langle\overline{w}_{t}-w^{\ast},(\overline{y}_{t+1}-\overline{y}_{t})\rangle|$.
	As in the proof for the strongly convex and smooth case, with appropriate
	choice of constant $K$ depending on the other constants, we first
	show that 
	\begin{align*}
	\mathbb{E}\|\overline{w}_{t+1}-w^{\ast}\|^{2} & \leq K^{2}
	\end{align*}
	for all $t$, i.e. the updates always stay in a large ball around
	the optimum during the Nesterov accelerated gradient descent. Note
	that $(F(\overline{w}_{t})-F^{\ast})\geq0$ and 
	\begin{align*}
	\beta_{t}\mathbb{E}\langle\overline{w}_{t}-w^{\ast},(\overline{y}_{t+1}-\overline{y}_{t})\rangle & \leq\beta_{t}\sqrt{\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}}\cdot\sqrt{\mathbb{E}\|\overline{y}_{t+1}-\overline{y}_{t}\|^{2}}
	\end{align*}
	so that 
	\begin{align*}
	\mathbb{E}\|\overline{w}_{t+1}-w^{\ast}\|^{2} & \leq(1-\alpha_{t}\mu)\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}+\alpha_{t}^{2}B+2\beta_{t}\sqrt{\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}}\cdot\sqrt{\mathbb{E}\|\overline{y}_{t+1}-\overline{y}_{t}\|^{2}}\\
	& \leq(1-\alpha_{t}\mu)\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}+\alpha_{t}^{2}B+2\beta_{t}\sqrt{\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}}\cdot G
	\end{align*}
	and again we can conclude that $\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}\leq K^{2}$
	for $t\geq0$, for $K$ satisfying 
	\begin{align*}
	\alpha_{0}B+2K\cdot G & \leq\mu K^{2}
	\end{align*}
	and
	\begin{align*}
	\|w_{0}-w^{\ast}\|^{2} & \leq K^{2}
	\end{align*}
	
	Finally, the bound on $\beta_{t}\mathbb{E}\langle\overline{w}_{t}-w^{\ast},(\overline{y}_{t+1}-\overline{y}_{t})\rangle$
	is exactly the same as in the proof for the strongly convex and smooth
	case, and we may conclude that 
	\begin{align*}
	\mathbb{E}\|\overline{w}_{t+1}-w^{\ast}\|^{2} & \leq(1-\mu\alpha_{t})\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}+\alpha_{t}^{2}B'-2\alpha_{t}\mathbb{E}(F(\overline{w}_{t})-F^{\ast})
	\end{align*}
	where 
	\begin{align*}
	B' & =B+2K^{2}\\
	& =6G^{2}+32(E-1)^{2}G^{2}+2K^{2}
	\end{align*}
	
	To conclude the proof, we apply the averaging trick of \textbf{TODO:CITE
		LACOSTE }to get \textbf{
		\begin{align*}
		F(\sum_{t=1}^{T}\frac{2t}{T(T+1)}\overline{w}_{t})-F^{\ast} & \leq\frac{2B'}{\mu(T+1)}
		\end{align*}
	}
\end{proof}
%
We now move on to prove the result in the case of partial participation.
Now the FedAvg algorithm with Nesterov Accelerated SGD (NASGD) follows
the updates
\begin{align*}
y_{t+1}^{k} & =w_{t}^{k}-\alpha_{t}g_{t,k}\\
w_{t+1}^{k} & =\begin{cases}
y_{t+1}^{k}+\beta_{t}(y_{t+1}^{k}-y_{t}^{k}) & \text{if }t+1\notin\mathcal{I}_{E}\\
\sum_{k\in\mathcal{S}_{t+1}}\left(y_{t+1}^{k}+\beta_{t}(y_{t+1}^{k}-y_{t}^{k})\right) & \text{if }t+1\in\mathcal{I}_{E}
\end{cases}
\end{align*}
where $\mathcal{S}_{t+1}$ is the multiset obtained by sampling from
$[N]$ according to $p_{k}$, \emph{with replacement, }a total of
$S=|\mathcal{S}_{t+1}|$ times. 

As before we define the virtual sequences $\overline{y}_{t}=\sum_{k=1}^{N}p_{k}y_{t}^{k}$,
$\overline{w}_{t}=\sum_{k=1}^{N}p_{k}w_{t}^{k}$, and $\overline{g}_{t}=\sum_{k=1}^{N}p_{k}\mathbb{E}g_{t,k}$.
We have $\mathbb{E}g_{t}=\overline{g}_{t}$ and $\overline{y}_{t+1}=\overline{w}_{t}-\alpha_{t}g_{t}$,
and as in the full participation case, $\overline{w}_{t+1}=\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t})$
for $t+1\notin\mathcal{I}_{E}$. When $t+1$ is a communication round,
because of the sampling step, this identity is no longer true, but
is true when we take expectation with respect to the sampling distribution
$\mathbb{P}_{\mathcal{S}_{t+1}}$. 
\begin{theorem}
	(Partial device participation) Suppose $F_{k}$ is $\mu$-strongly
	convex for all $k$. Let $E$ be the communication interval, and learning
	rates 
	\begin{align*}
	\alpha_{t} & =\frac{c}{\mu(E+t)}\\
	\beta_{t} & \leq\alpha_{t}
	\end{align*}
	so that $\alpha_{t}\leq2\alpha_{t+E}$, and where $c$ is small enough
	such that the following hold: 
	\begin{align*}
	\alpha_{t}^{2}+\beta_{t-1}^{2} & \leq\frac{1}{2}\\
	4\alpha_{t-1}^{2} & \leq\alpha_{t}
	\end{align*}
	for all $t\geq0$. Suppose also that $G$ is a constant satisfying
	$\mathbb{E}\|w_{0}-\alpha_{0}g_{0,k}\|^{2}=\mathbb{E}\|w_{0}-\alpha_{0}\nabla F_{k}(w_{0},\xi_{0}^{k})\|^{2}\leq G^{2}$
	for all $k$, and $\mathbb{E}\|\nabla F_{k}(w,\xi_{t}^{k})\|^{2}\leq G^{2}$
	for $w=\overline{w}_{t}$ or $w=w_{t}^{k}$ and all $t,k$.
	
	Then with partial device participation, \textbf{
		\begin{align*}
		F(\sum_{t=1}^{T}\frac{2t}{T(T+1)}\overline{w}_{t})-F^{\ast} & \leq\frac{2(B'+C)}{\mu(T+1)}
		\end{align*}
	} where
	\begin{align*}
	B' & =6G^{2}+32(E-1)^{2}G^{2}+2K^{2}\\
	C & =\frac{16}{S}E^{2}G^{2}
	\end{align*}
	and $K$ is such that 
	\begin{align*}
	\alpha_{0}B+2K\cdot G & \leq\mu K^{2}\\
	B & =6G^{2}+32(E-1)^{2}G^{2}
	\end{align*}
	and
	\begin{align*}
	K & \geq\max\{\|w_{0}-w^{\ast}\|^{2},\frac{G}{2\alpha_{0}}\}
	\end{align*}
\end{theorem}
%
\begin{proof}
	We have
	\begin{align*}
	\|\overline{w}_{t+1}-w^{\ast}\|^{2} & =\|\overline{w}_{t+1}-(\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t}))+(\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t}))-w^{\ast}\|^{2}\\
	& =\|\overline{w}_{t+1}-(\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t}))\|^{2}+\|(\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t}))-w^{\ast}\|^{2}\\
	& +2\langle\overline{w}_{t+1}-(\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t})),(\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t}))-w^{\ast}\rangle
	\end{align*}
	
	Note that 
	\begin{align*}
	\mathbb{E}_{\mathcal{S}_{t+1}}\langle\overline{w}_{t+1}-(\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t})),(\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t}))-w^{\ast}\rangle & =0
	\end{align*}
	since 
	\begin{align*}
	\mathbb{E}_{\mathcal{S}_{t+1}}\overline{w}_{t+1} & =\mathbb{E}_{\mathcal{S}_{t+1}}\frac{1}{S}\sum_{k\in\mathcal{S}_{t+1}}(y_{t+1}^{k}+\beta_{t}(y_{t+1}^{k}-y_{t}^{k}))\\
	& =\frac{1}{S}\sum_{k\in\mathcal{S}_{t+1}}\mathbb{E}_{\mathcal{S}_{t+1}}(y_{t+1}^{k}+\beta_{t}(y_{t+1}^{k}-y_{t}^{k}))\\
	& =\frac{1}{S}\cdot S\cdot\sum_{k=1}^{N}p_{k}(y_{t+1}^{k}+\beta_{t}(y_{t+1}^{k}-y_{t}^{k}))\\
	& =\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t})
	\end{align*}
	Moreover, if $t+1\notin\mathcal{I}_{E}$, $\|\overline{w}_{t+1}-(\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t}))\|^{2}=0$
	as well, while if $t+1\notin\mathcal{I}_{E}$, we show that 
	\begin{align*}
	\mathbb{E}\|\overline{w}_{t+1}-(\overline{y}_{t+1}+\beta_{t}(\overline{y}_{t+1}-\overline{y}_{t}))\|^{2} & \leq\frac{16}{S}\alpha_{t}^{2}E^{2}G^{2}
	\end{align*}
	using the same proof as the strongly convex and smooth case. Moreover,
	\begin{align*}
	\mathbb{E}\|\overline{w}_{t+1}-w^{\ast}\|^{2} & \leq(1-\mu\alpha_{t})\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}+\alpha_{t}^{2}B'-2\alpha_{t}\mathbb{E}(F(\overline{w}_{t})-F^{\ast})
	\end{align*}
	by the proof from the full participation case. Now we can conclude
	that 
	\begin{align*}
	\mathbb{E}\|\overline{w}_{t+1}-w^{\ast}\|^{2} & \leq(1-\mu\alpha_{t})\mathbb{E}\|\overline{w}_{t}-w^{\ast}\|^{2}+\alpha_{t}^{2}(B'+C)-2\alpha_{t}\mathbb{E}(F(\overline{w}_{t})-F^{\ast})
	\end{align*}
	where 
	\begin{align*}
	C & =\frac{16}{S}E^{2}G^{2}
	\end{align*}
	
	The proof then following by applying the averaging trick from the
	full participation case replacing $B'$ with $B'+C$.
\end{proof}